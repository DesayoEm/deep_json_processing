{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "41605e85-22b1-4de5-bb6b-d96a8c6fead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Any, Hashable, Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "175d0259-8edb-4167-84e4-5ce3635546b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGLE_FIELDS = {\n",
    "    # Identification\n",
    "    \"nct_id\": \"protocolSection.identificationModule.nctId\",\n",
    "    \"brief_title\": \"protocolSection.identificationModule.briefTitle\",\n",
    "    \"official_title\": \"protocolSection.identificationModule.officialTitle\",\n",
    "    \"acronym\": \"protocolSection.identificationModule.acronym\",\n",
    "    \"org_study_id\": \"protocolSection.identificationModule.orgStudyIdInfo.id\",\n",
    "    # Description\n",
    "    \"brief_summary\": \"protocolSection.descriptionModule.briefSummary\",\n",
    "    \"detailed_desc\": \"protocolSection.descriptionModule.detailedDescription\",\n",
    "\n",
    "    # Sponsor\n",
    "    \"responsible_party\": \"protocolSection.sponsorCollaboratorsModule.responsibleParty.type\",\n",
    "    \n",
    "    # Design (single values)\n",
    "    \"study_type\": \"protocolSection.designModule.studyType\",\n",
    "    \"patient_registry\": \"protocolSection.designModule.patientRegistry\",\n",
    "    \"enrollment_type\": \"protocolSection.designModule.enrollmentInfo.type\",\n",
    "    \"enrollment_count\": \"protocolSection.designModule.enrollmentInfo.count\",\n",
    "    \"design_allocation\": \"protocolSection.designModule.designInfo.allocation\",\n",
    "    \"design_intervention_model\": \"protocolSection.designModule.designInfo.interventionModel\",\n",
    "    \"design_intervention_model_desc\": \"protocolSection.designModule.designInfo.interventionModelDescription\",\n",
    "    \"design_primary_purpose\": \"protocolSection.designModule.designInfo.primaryPurpose\",\n",
    "    \"design_observational_model\": \"protocolSection.designModule.designInfo.observationalModel\",\n",
    "    \"design_time_perspective\": \"protocolSection.designModule.designInfo.timePerspective\",\n",
    "    \"design_masking\": \"protocolSection.designModule.designInfo.maskingInfo.masking\",\n",
    "    # Biospecimen\n",
    "    \"biospec_retention\": \"protocolSection.designModule.bioSpec.retention\",\n",
    "    \"biospec_desc\": \"protocolSection.designModule.bioSpec.description\",\n",
    "    # Eligibility\n",
    "    \"eligibility_criteria\": \"protocolSection.eligibilityModule.eligibilityCriteria\",\n",
    "    \"healthy_volunteers\": \"protocolSection.eligibilityModule.healthyVolunteers\",\n",
    "    \"sex\": \"protocolSection.eligibilityModule.sex\",\n",
    "    \"min_age\": \"protocolSection.eligibilityModule.minimumAge\",\n",
    "    \"max_age\": \"protocolSection.eligibilityModule.maximumAge\",\n",
    "    \"population_desc\": \"protocolSection.eligibilityModule.studyPopulation\",\n",
    "    \"sampling_method\": \"protocolSection.eligibilityModule.samplingMethod\",\n",
    "    # Status\n",
    "    \"overall_status\": \"protocolSection.statusModule.overallStatus\",\n",
    "    \"last_known_status\": \"protocolSection.statusModule.lastKnownStatus\",\n",
    "    \"status_verified_date\": \"protocolSection.statusModule.statusVerifiedDate\",\n",
    "    \"start_date\": \"protocolSection.statusModule.startDateStruct.date\",\n",
    "    \"start_date_type\": \"protocolSection.statusModule.startDateStruct.type\",\n",
    "    \"first_submit_date\": \"protocolSection.statusModule.studyFirstSubmitDate\",\n",
    "    \"last_update_submit_date\": \"protocolSection.statusModule.lastUpdateSubmitDate\",\n",
    "    \"completion_date\": \"protocolSection.statusModule.completionDateStruct.date\",\n",
    "    \"completion_date_type\": \"protocolSection.statusModule.completionDateStruct.type\",\n",
    "    \"why_stopped\": \"protocolSection.statusModule.whyStopped\",\n",
    "    \"has_expanded_access\": \"protocolSection.statusModule.expandedAccessInfo.hasExpandedAccess\",\n",
    "    # Oversight\n",
    "    \"has_dmc\": \"protocolSection.oversightModule.oversightHasDmc\",\n",
    "    \"is_fda_regulated_drug\": \"protocolSection.oversightModule.isFdaRegulatedDrug\",\n",
    "    \"is_fda_regulated_device\": \"protocolSection.oversightModule.isFdaRegulatedDevice\",\n",
    "    \"is_unapproved_device\": \"protocolSection.oversightModule.isUnapprovedDevice\",\n",
    "    \"is_us_export\": \"protocolSection.oversightModule.isUsExport\",\n",
    "    # Individual participant data\n",
    "    \"ipd_sharing\": \"protocolSection.ipdSharingStatementModule.ipdSharing\",\n",
    "    \"ipd_desc\": \"protocolSection.ipdSharingStatementModule.description\",\n",
    "    \"ipd_time_frame\": \"protocolSection.ipdSharingStatementModule.timeFrame\",\n",
    "    \"ipd_access_criteria\": \"protocolSection.ipdSharingStatementModule.accessCriteria\",\n",
    "    \"ipd_url\": \"protocolSection.ipdSharingStatementModule.url\",\n",
    "    # Miscellaneous\n",
    "    \"version_holder\": \"derivedSection.miscInfoModule.versionHolder\",\n",
    "    \"has_results\": \"hasResults\",\n",
    "    \"last_updated\": \"protocolSection.statusModule.lastUpdatePostDateStruct.date\",\n",
    "    \"limitations_desc\": \"resultsSection.moreInfoModule.limitationsAndCaveats.description\",\n",
    "    # Certain agreements\n",
    "    \"certain_agreement_pi_sponsor_employee\": \"resultsSection.moreInfoModule.certainAgreement.piSponsorEmployee\",\n",
    "    \"certain_agreement_restrictive\": \"resultsSection.moreInfoModule.certainAgreement.restrictiveAgreement\",\n",
    "    \"certain_agreement_other_details\": \"resultsSection.moreInfoModule.certainAgreement.otherDetails\",\n",
    "    \"certain_agreement_restriction_type\": \"resultsSection.moreInfoModule.certainAgreement.restrictionType\",\n",
    "    # Point of contact\n",
    "    \"poc_title\": \"resultsSection.moreInfoModule.pointOfContact.title\",\n",
    "    \"poc_organization\": \"resultsSection.moreInfoModule.pointOfContact.organization\",\n",
    "    \"poc_email\": \"resultsSection.moreInfoModule.pointOfContact.email\",\n",
    "    \"poc_phone\": \"resultsSection.moreInfoModule.pointOfContact.phone\",\n",
    "    \"poc_phone_ext\": \"resultsSection.moreInfoModule.pointOfContact.phoneExt\",\n",
    "    # Submission tracking\n",
    "    \"sub_tracking_estimated_results_date\": \"derivedSection.miscInfoModule.submissionTracking.estimatedResultsFirstSubmitDate\",\n",
    "}\n",
    "\n",
    "NESTED_FIELDS = {\n",
    "    \"sponsor\": {\n",
    "        \"index_field\": \"protocolSection.sponsorCollaboratorsModule.leadSponsor\",\n",
    "        \"object_type\": \"simple dict\",\n",
    "        \"fields\": [\n",
    "            (\"lead_sponsor_name\", \"name\"),\n",
    "            (\"lead_sponsor_class\", \"class\"),\n",
    "        ],\n",
    "        \"table_name\": \"sponsors\",\n",
    "        \"bridge_table_name\": \"study_sponsors\",\n",
    "        \"transformer_method\": \"extract_sponsors\",\n",
    "    },\n",
    "    \"collaborators\": {\n",
    "        \"index_field\": \"protocolSection.sponsorCollaboratorsModule.collaborators\",\n",
    "        \"object_type\": \"array_of_dicts\",\n",
    "        \"fields\": [\n",
    "            (\"sponsor_name\", \"name\"),\n",
    "            (\"sponsor_class\", \"class\"),\n",
    "        ],\n",
    "        \"table_name\": \"sponsor\",\n",
    "        \"bridge_table_name\": \"study_sponsors\",\n",
    "        \"transformer_method\": \"extract_sponsors\",\n",
    "    },\n",
    "    \"conditions\": {\n",
    "        \"index_field\": \"protocolSection.conditionsModule.conditions\",\n",
    "        \"object_type\": \"simple_array\",\n",
    "        \"table_name\": \"conditions\",\n",
    "        \"bridge_table_name\": \"bridge_study_conditions\",\n",
    "        \"field_name\": \"condition_name\",\n",
    "        \"transformer_method\": \"extract_conditions\",\n",
    "    },\n",
    "    \"keywords\": {\n",
    "        \"index_field\": \"protocolSection.conditionsModule.keywords\",\n",
    "        \"object_type\": \"simple_array\",\n",
    "        \"table_name\": \"keywords\",\n",
    "        \"bridge_table_name\": \"bridge_study_keywords\",\n",
    "        \"field_name\": \"keyword\",\n",
    "        \"transformer_method\": \"extract_keywords\",\n",
    "    },\n",
    "    \"interventions\": {\n",
    "        \"index_field\": \"protocolSection.armsInterventionsModule.interventions\",\n",
    "        \"object_type\": \"array_of_dicts\",\n",
    "        \"fields\": [\n",
    "            (\"intervention_name\", \"name\"),\n",
    "            (\"intervention_desc\", \"description\"),\n",
    "            (\"intervention_type\", \"type\"),\n",
    "        ],\n",
    "        \"nested\": {\n",
    "            \"otherNames\": {\n",
    "                \"object_type\": \"nested_simple_array\",\n",
    "                \"table_name\": \"interventions\",\n",
    "                \"bridge_table_name\": \"bridge_table_name\",\n",
    "            }\n",
    "        },\n",
    "        \"table_name\": \"interventions\",\n",
    "        \"bridge_table_name\": \"bridge_study_interventions\",\n",
    "        \"transformer_method\": \"extract_interventions\",\n",
    "    },\n",
    "    \"arm_groups\": {\n",
    "        \"index_field\": \"protocolSection.armsInterventionsModule.armGroups\",\n",
    "        \"object_type\": \"array_of_dicts\",\n",
    "        \"table_name\": \"study_arm_groups\",\n",
    "        \"fields\": [\n",
    "            (\"arm_group_label\", \"label\"),\n",
    "            (\"arm_group_type\", \"type\"),\n",
    "            (\"arm_group_desc\", \"description\"),\n",
    "        ],\n",
    "        \"nested\": {\n",
    "            \"interventionNames\": {\n",
    "                \"object_type\": \"nested_simple_array\",\n",
    "                \"bridge_table_name\": \"arm_group_interventions\",\n",
    "                \"field_name\": \"intervention_name\",\n",
    "            },\n",
    "        \"transformer_method\": \"extract_arm_groups\",\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"central_contacts\": {\n",
    "        \"index_field\": \"protocolSection.contactsLocationsModule.centralContacts\",\n",
    "        \"object_type\": \"array_of_dicts\",\n",
    "        \"table_name\": \"contacts\",\n",
    "        \"bridge_table_name\": \"study_contacts\",\n",
    "        \"fields\": [\n",
    "            (\"name\", \"name\"),\n",
    "            (\"role\", \"role\"),\n",
    "            (\"email\", \"email\"),\n",
    "            (\"phone\", \"phone\"),\n",
    "            (\"phoneExt\", \"phoneExt\"),\n",
    "        ],\n",
    "        \"transformer_method\": \"extract_central_contacts\",\n",
    "    },\n",
    "    \"locations\": {\n",
    "        \"index_field\": \"protocolSection.contactsLocationsModule.locations\",\n",
    "        \"object_type\": \"array_of_dicts\",\n",
    "        \"table_name\": \"sites\",\n",
    "        \"bridge_table_name\": \"study_sites\",\n",
    "        \"fields\": [\n",
    "            (\"site_facility\", \"facility\"),\n",
    "            (\"city\", \"city\"),\n",
    "            (\"state\", \"state\"),\n",
    "            (\"zip\", \"zip\"),\n",
    "            (\"country\", \"country\"),\n",
    "            (\"site_status\", \"status\"),\n",
    "        ],\n",
    "        \"nested\": {\n",
    "            \"geoPoint\": {\n",
    "                \"object_type\": \"simple_dict\",\n",
    "                \"fields\": [\"lat\", \"lon\"],\n",
    "            },\n",
    "            #contacts are saved as a JSON blob\n",
    "            \"contacts\": {\n",
    "                \"object_type\": \"nested_array_of_dicts\",\n",
    "                \"table_name\": \"contacts\",\n",
    "                \"bridge_table_name\": \"location_contacts\",\n",
    "                \"fields\": [\n",
    "                    (\"name\", \"name\"),\n",
    "                    (\"role\", \"role\"),\n",
    "                    (\"email\", \"email\"),\n",
    "                    (\"phone\", \"phone\"),\n",
    "                    (\"phoneExt\", \"phoneExt\"),\n",
    "                ],\n",
    "                \"transformer_method\": \"extract_contacts\",\n",
    "            },\n",
    "        },\n",
    "        \"transformer_method\": \"extract_locations\",\n",
    "    }\n",
    "\n",
    "    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2ac33a24-4e17-4358-942e-0b32aa4030a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_key(*args) -> str:\n",
    "    \"\"\"Generates a deterministic surrogate key from input values.\"\"\"\n",
    "    combined = \"|\".join(str(arg) for arg in args if arg is not None)\n",
    "    return hashlib.sha256(combined.encode()).hexdigest()[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6acc5cf7-14a8-4164-9904-a69251bbd15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_study_fields(study_key: str, study_data: pd.Series) -> Dict:\n",
    "    study_record = dict()\n",
    "\n",
    "    study_record['study_key'] = study_key\n",
    "    for entity_key in SINGLE_FIELDS:\n",
    "        index_field = SINGLE_FIELDS.get(entity_key)\n",
    "\n",
    "        study_record[entity_key] = study_data.get(index_field)\n",
    "\n",
    "    return study_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1eed3fbe-1ba6-4f19-bfe0-b61e60918e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sponsors(idx: int, study_key: str, study_data: pd.Series):\n",
    "\n",
    "    sponsors = []\n",
    "    study_sponsors = []\n",
    "\n",
    "    # Extract lead sponsor\n",
    "    lead_sponsor_index = NESTED_FIELDS[\"sponsor\"][\"index_field\"]\n",
    "\n",
    "    # sponsor name and class are scalar values and MUST be extracted directly\n",
    "    lead_sponsor_name = study_data.get(f'{lead_sponsor_index}.name')\n",
    "    lead_sponsor_class = study_data.get(f'{lead_sponsor_index}.class')\n",
    "\n",
    "    if pd.notna(lead_sponsor_name) and pd.notna(lead_sponsor_class):\n",
    "        sponsor_key = generate_key(\n",
    "            lead_sponsor_name, lead_sponsor_class\n",
    "        )\n",
    "        sponsors.append(\n",
    "            {\n",
    "                \"sponsor_key\": sponsor_key,\n",
    "                \"name\": lead_sponsor_name,\n",
    "                \"sponsor_class\": lead_sponsor_class,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        study_sponsors.append(\n",
    "            {\"study_key\": study_key, \"sponsor_key\": sponsor_key, \"is_lead\": True}\n",
    "        )\n",
    "    else:\n",
    "        print(f\"No lead sponsor found for {idx}\")\n",
    "\n",
    "    # Extract collaborators\n",
    "    collaborators_index = NESTED_FIELDS[\"collaborators\"][\"index_field\"]\n",
    "    collaborators_list = study_data.get(collaborators_index)\n",
    "\n",
    "    if isinstance(collaborators_list, (list, np.ndarray)) and len(collaborators_list) > 0:\n",
    "        for collaborator in collaborators_list:\n",
    "            sponsor_key = generate_key(\n",
    "                collaborator.get(\"name\"), collaborator.get(\"class\")\n",
    "            )\n",
    "\n",
    "            sponsors.append(\n",
    "                {\n",
    "                    \"sponsor_key\": sponsor_key,\n",
    "                    \"name\": collaborator.get(\"name\"),\n",
    "                    \"sponsor_class\": collaborator.get(\"class\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            study_sponsors.append(\n",
    "                {\"study_key\": study_key, \"sponsor_key\": sponsor_key, \"is_lead\": False}\n",
    "            )\n",
    "\n",
    "    return sponsors, study_sponsors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3256cf6a-aaab-43e9-af9b-85e9c7c7a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_conditions(idx: int, study_key: str, study_data: pd.Series) -> Tuple | None:\n",
    "    conditions = []\n",
    "    study_conditions = []\n",
    "\n",
    "    conditions_index = NESTED_FIELDS[\"conditions\"][\"index_field\"]\n",
    "    conditions_list = study_data.get(conditions_index)\n",
    "\n",
    "\n",
    "    if isinstance(conditions_list, (list, np.ndarray)) and len(conditions_list) > 0:\n",
    "        for condition in conditions_list:\n",
    "            condition_key = generate_key(condition)\n",
    "\n",
    "            conditions.append(\n",
    "                {\"condition_key\": condition_key, \"condition_name\": condition}\n",
    "            )\n",
    "\n",
    "            study_conditions.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"condition_key\": condition_key,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return conditions, study_conditions\n",
    "\n",
    "    print(f\"No conditions found for {idx}\")\n",
    "    return conditions, study_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cfb68545-c0da-4f92-a5cd-8ef7dc91c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(idx: Hashable, study_key: str, study_data: pd.Series) -> Tuple:\n",
    "    keywords = []\n",
    "    study_keywords = []\n",
    "\n",
    "    keywords_index = NESTED_FIELDS[\"keywords\"][\"index_field\"]\n",
    "    keywords_list = study_data.get(keywords_index)\n",
    "    if isinstance(keywords_list, (list, np.ndarray)) and len(keywords_list) > 0:\n",
    "        for keyword in keywords_list:\n",
    "            keyword_key = generate_key(keyword)\n",
    "\n",
    "            keywords.append({\"keyword_key\": keyword_key, \"keyword_name\": keyword})\n",
    "\n",
    "            study_keywords.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"keyword_key\": keyword_key,\n",
    "                }\n",
    "            )\n",
    "        \n",
    "    return keywords, study_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f216152b-1ece-485e-bbd0-b09970159515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_interventions(idx: Hashable, study_key: str, study_data: pd.Series) -> Tuple:\n",
    "    intervention_names = []\n",
    "    study_interventions = []\n",
    "\n",
    "    interventions_index = NESTED_FIELDS[\"interventions\"][\"index_field\"]\n",
    "    interventions_list = study_data.get(interventions_index)\n",
    "\n",
    "    if isinstance(interventions_list, (list, np.ndarray)) and len(interventions_list) > 0:\n",
    "        for intervention in interventions_list:\n",
    "            main_name = intervention.get(\"name\")\n",
    "            intervention_type = intervention.get(\"type\")\n",
    "            description = intervention.get(\"description\")\n",
    "\n",
    "            intervention_key = generate_key(main_name, intervention_type)\n",
    "            intervention_names.append({\n",
    "                \"intervention_key\": intervention_key,\n",
    "                \"intervention_name\": main_name,\n",
    "                \"intervention_type\": intervention_type,\n",
    "                \"description\": description,\n",
    "               \n",
    "            })\n",
    "\n",
    "            study_interventions.append({\n",
    "                \"study_key\": study_key,\n",
    "                \"intervention_key\": intervention_key,\n",
    "                \"is_primary_name\": True\n",
    "            })\n",
    "\n",
    "\n",
    "            other_names = intervention.get(\"otherNames\")\n",
    "            if isinstance(other_names, (list, np.ndarray)) and len(other_names) > 0:\n",
    "                \n",
    "                for other_name in other_names:\n",
    "                    if other_name == main_name:\n",
    "                        continue #some studies put the main name in the list of other names\n",
    "                    intervention_key = generate_key(other_name, intervention_type)\n",
    "                    intervention_names.append({\n",
    "                        \"intervention_key\": intervention_key,\n",
    "                        \"intervention_name\": other_name,\n",
    "                        \"intervention_type\": intervention_type,\n",
    "                        \"description\": description,  # inherits from parent\n",
    "                       \n",
    "                    })\n",
    "\n",
    "                    study_interventions.append({\n",
    "                        \"study_key\": study_key,\n",
    "                        \"intervention_key\": intervention_key,\n",
    "                         \"is_primary_name\": False\n",
    "                    })\n",
    "    else:\n",
    "        pass\n",
    "        # print(f\"No interventions found for study {study_key}, {idx}\")\n",
    "    return intervention_names, study_interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e5266ee0-27ba-4442-8bcf-b67852cce434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_arm_groups(idx: Hashable, study_key: str, study_data: pd.Series) -> List | None:\n",
    "    study_arms_interventions = []\n",
    "\n",
    "    study_arms_index = NESTED_FIELDS[\"arm_groups\"][\"index_field\"]\n",
    "    study_arms_list = study_data.get(study_arms_index)\n",
    "\n",
    "    if isinstance(study_arms_list, (list, np.ndarray)) and len(study_arms_list) > 0:\n",
    "        for study_arm in study_arms_list:\n",
    "            study_arm_label = study_arm.get(\"label\")\n",
    "            study_arm_description = study_arm.get(\"description\")\n",
    "            study_arm_type = study_arm.get(\"type\")\n",
    "\n",
    "            arm_intervention_key = generate_key(study_key, study_arm_label, study_arm_description,\n",
    "                                                     study_arm_type)\n",
    "            \n",
    "            arm_interventions = study_arm.get(\"interventionNames\")\n",
    "            if isinstance(arm_interventions, (list, np.ndarray)) and len(arm_interventions) > 0:\n",
    "\n",
    "                for intervention in arm_interventions:\n",
    "                    study_arms_interventions.append(\n",
    "                        {\n",
    "                            \"study_key\": study_key,\n",
    "                            \"arm_intervention_key\": arm_intervention_key,\n",
    "                            \"arm_label\": study_arm_label,\n",
    "                            \"arm_description\": study_arm_description,\n",
    "                            \"arm_type\": study_arm_type,\n",
    "                            \"arm_intervention_name\": intervention,\n",
    "                        }\n",
    "                    )\n",
    "            else:\n",
    "                study_arms_interventions.append(\n",
    "                    {\n",
    "                        \"study_key\": study_key,\n",
    "                        \"arm_intervention_key\": arm_intervention_key,\n",
    "                        \"arm_label\": study_arm_label,\n",
    "                        \"arm_description\": study_arm_description,\n",
    "                        \"arm_type\": study_arm_type,\n",
    "                        \"arm_intervention_name\": None,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return study_arms_interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "79d49e8b-f99a-45bf-994b-331d0acbdaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_central_contacts(idx: Hashable, study_key: str, study_data: pd.Series) -> Tuple:\n",
    "    central_contacts = []\n",
    "    study_central_contacts = []\n",
    "\n",
    "    central_contacts_index = NESTED_FIELDS[\"central_contacts\"][\"index_field\"]\n",
    "    central_contacts_list = study_data.get(central_contacts_index)\n",
    "\n",
    "    if isinstance(central_contacts_list, (list, np.ndarray)) and len(central_contacts_list) > 0:\n",
    "\n",
    "        for central_contact in central_contacts_list:\n",
    "            name = central_contact.get(\"name\")\n",
    "            role = central_contact.get(\"role\")\n",
    "            phone = central_contact.get(\"phone\")\n",
    "            email = central_contact.get(\"email\")\n",
    "\n",
    "            central_contact_key = generate_key(name, role, phone, email)\n",
    "\n",
    "            central_contacts.append(\n",
    "                {\"contact_key\": central_contact_key,\n",
    "                 \"contact_name\": name,\n",
    "                 \"contact_role\": role,\n",
    "                 \"contact_phone\": phone,\n",
    "                 \"contact_email\": email,\n",
    "                 })\n",
    "\n",
    "            study_central_contacts.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"contact_key\": central_contact_key,\n",
    "                }\n",
    "            )\n",
    "    return central_contacts, study_central_contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "67b65fd9-6808-450e-acd0-e3d964bb40f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_locations(idx: Hashable, study_key: str, study_data: pd.Series) -> Tuple:\n",
    "    \"\"\"\n",
    "    Extract locations and stores location contact as JSON blob.\n",
    "\n",
    "    NOTE: Officials are stored denormalized as JSON since not used for filtering/analysis.\n",
    "    Avoids snowflaking the schema while preserving all contact information for downstream applications.\n",
    "    \"\"\"\n",
    "    locations = []\n",
    "    study_locations = []\n",
    "\n",
    "    locations_index = NESTED_FIELDS[\"locations\"][\"index_field\"]\n",
    "    locations_list = study_data.get(locations_index)\n",
    "\n",
    "\n",
    "    if isinstance(locations_list, (list, np.ndarray)) and len(locations_list) > 0:\n",
    "\n",
    "        for location in locations_list:\n",
    "            facility = location.get(\"facility\")\n",
    "            city = location.get(\"city\")\n",
    "            state = location.get(\"state\")\n",
    "            country = location.get(\"country\")\n",
    "\n",
    "            location_key = generate_key(facility, city, state, country)\n",
    "            \n",
    "            curr_location = {\n",
    "                \"location_key\": location_key,\n",
    "                 \"status\": location.get(\"status\"),\n",
    "                 \"facility\": facility,\n",
    "                 \"city\": city,\n",
    "                 \"state\": state,\n",
    "                 \"country\": country,\n",
    "                 \"contacts\": location.get(\"contacts\"), #json blob\n",
    "                 }\n",
    "            \n",
    "            geopoint = location.get(\"geoPoint\")\n",
    "            if isinstance(geopoint, (dict, np.ndarray)) and len(geopoint) > 0:\n",
    "                curr_location[\"lat\"] = geopoint.get(\"lat\"),\n",
    "                curr_location[\"lon\"] = geopoint.get(\"lon\")\n",
    "\n",
    "            locations.append(curr_location)\n",
    "\n",
    "            \n",
    "\n",
    "            study_locations.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"location_key\": location_key,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return locations, study_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "563cd50a-5e2d-4c23-8203-db7d8926fdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "STUDIES 1000\n",
      "----------------\n",
      "SPONSORS 1631\n",
      "DEDUPED SPONSORS 1176\n",
      "STUDY SPONSORS 1631\n",
      "DEDUPED STUDY SPONSORS 1631\n",
      "----------------\n",
      "CONDITIONS 1754\n",
      "DEDUPED CONDITIONS 1355\n",
      "STUDY CONDITIONS 1754\n",
      "DEDUPED STUDY CONDITIONS 1754\n",
      "----------------\n",
      "KEYWORDS 2419\n",
      "DEDUPED KEYWORDS 2235\n",
      "STUDY KEYWORDS 2419\n",
      "DEDUPED STUDY KEYWORDS 2419\n",
      "----------------\n",
      "INTERVENTIONS 2740\n",
      "DEDUPED INTERVENTIONS 2400\n",
      "STUDY INTERVENTIONS 2740\n",
      "DEDUPED STUDY INTERVENTIONS 2668\n",
      "----------------\n",
      "ARM GROUPS INTERVENTION 2426\n",
      "DEDUPED ARM GROUPS INTERVENTION 2426\n",
      "----------------\n",
      "LOCATIONS 5247\n",
      " DEDUPED LOCATIONS 4782\n",
      " STUDY LOCATIONS 5247\n",
      " DEDUPED STUDY LOCATIONS 5180\n",
      "----------------\n",
      "CONTACTS 381\n",
      " DEDUPED CONTACTS 380\n",
      "STUDY CONTACTS 381\n",
      "DEDUPED STUDY CONTACTS 381\n"
     ]
    }
   ],
   "source": [
    "all_studies = []\n",
    "all_sponsors = []\n",
    "all_study_sponsors = []\n",
    "\n",
    "all_conditions = []\n",
    "all_study_conditions = []\n",
    "\n",
    "all_keywords = []\n",
    "all_study_keywords = []\n",
    "\n",
    "all_arm_group_interventions = []\n",
    "\n",
    "all_interventions = []\n",
    "all_interventions_other_names = []\n",
    "all_study_interventions = []\n",
    "\n",
    "all_locations = []\n",
    "all_study_locations = []\n",
    "all_central_contacts = []\n",
    "all_study_central_contacts = []\n",
    "\n",
    "df = pd.read_parquet(\"1.parquet\")\n",
    "df_studies = pd.json_normalize(df['studies'].tolist())\n",
    "\n",
    "for idx, study in df_studies.iterrows():\n",
    "    nct_index = SINGLE_FIELDS['nct_id']\n",
    "    nct_id = study.get(nct_index)\n",
    "    \n",
    "    study_key = generate_key(nct_id)\n",
    "\n",
    "\n",
    "    #study\n",
    "    study_record = extract_study_fields(study_key, study)\n",
    "    all_studies.append(study_record)\n",
    "\n",
    "    # sponsors\n",
    "    sponsors, study_sponsors = extract_sponsors(idx, study_key, study)\n",
    "    all_sponsors.extend(sponsors)\n",
    "    all_study_sponsors.extend(study_sponsors)\n",
    "\n",
    "    # conditions and keywords\n",
    "    conditions, study_conditions = extract_conditions(idx, study_key, study)\n",
    "    all_conditions.extend(conditions)\n",
    "    all_study_conditions.extend(study_conditions)\n",
    "\n",
    "    keywords, study_keywords = extract_keywords(idx, study_key, study)\n",
    "    all_keywords.extend(keywords)\n",
    "    all_study_keywords.extend(study_keywords)\n",
    "\n",
    "\n",
    "    # groups and interventions\n",
    "    arm_group_interventions = extract_arm_groups(idx, study_key, study)\n",
    "    all_arm_group_interventions.extend(arm_group_interventions)\n",
    "\n",
    "    interventions, study_interventions = extract_interventions(idx, study_key, study)\n",
    "    all_interventions.extend(interventions)\n",
    "    all_study_interventions.extend(study_interventions)\n",
    "\n",
    "    # contacts and locations\n",
    "    central_contacts, study_central_contacts  = extract_central_contacts(idx, study_key, study)\n",
    "    all_central_contacts.extend(central_contacts)\n",
    "    all_study_central_contacts.extend(study_central_contacts)\n",
    "\n",
    "    locations, study_locations = extract_locations(idx, study_key, study)\n",
    "    all_locations.extend(locations)\n",
    "    all_study_locations.extend(study_locations)\n",
    "\n",
    "\n",
    "studies = pd.DataFrame(all_studies)\n",
    "\n",
    "df_sponsors = pd.DataFrame(all_sponsors)\n",
    "df_study_sponsors = pd.DataFrame(all_study_sponsors)\n",
    "\n",
    "df_conditions = pd.DataFrame(all_conditions)\n",
    "df_study_conditions= pd.DataFrame(all_study_conditions)\n",
    "\n",
    "df_keywords = pd.DataFrame(all_keywords)\n",
    "df_study_keywords = pd.DataFrame(all_study_keywords)\n",
    "\n",
    "df_arm_group_interventions = pd.DataFrame(all_arm_group_interventions)\n",
    "df_interventions = pd.DataFrame(all_interventions)\n",
    "df_study_interventions = pd.DataFrame(all_study_interventions)\n",
    "\n",
    "\n",
    "df_central_contacts = pd.DataFrame(all_central_contacts)\n",
    "df_study_central_contacts = pd.DataFrame(all_study_central_contacts)\n",
    "df_locations = pd.DataFrame(all_locations)\n",
    "df_study_locations = pd.DataFrame(all_study_locations)\n",
    "\n",
    "\n",
    "print(\"----------------\")\n",
    "print(f\"STUDIES {len(studies)}\")\n",
    "print(\"----------------\")\n",
    "\n",
    "\n",
    "#dedupe and inspect\n",
    "print(f\"SPONSORS {len(df_sponsors)}\")\n",
    "df_sponsors = df_sponsors.drop_duplicates(subset=[\"sponsor_key\"])\n",
    "print(f\"DEDUPED SPONSORS {len(df_sponsors)}\")\n",
    "\n",
    "print(f\"STUDY SPONSORS {len(df_study_sponsors)}\")\n",
    "df_study_sponsors = df_study_sponsors.drop_duplicates(subset=[\"sponsor_key\", \"study_key\"])\n",
    "print(f\"DEDUPED STUDY SPONSORS {len(df_study_sponsors)}\")\n",
    "print(\"----------------\")\n",
    "\n",
    "print(f\"CONDITIONS {len(df_conditions)}\")\n",
    "df_conditions = df_conditions.drop_duplicates(subset=[\"condition_key\"])\n",
    "print(f\"DEDUPED CONDITIONS {len(df_conditions)}\")\n",
    "\n",
    "print(f\"STUDY CONDITIONS {len(df_study_conditions)}\")\n",
    "df_study_conditions = df_study_conditions.drop_duplicates(subset=[\"condition_key\", \"study_key\"])\n",
    "print(f\"DEDUPED STUDY CONDITIONS {len(df_study_conditions)}\")\n",
    "print(\"----------------\")\n",
    "\n",
    "print(f\"KEYWORDS {len(df_keywords)}\")\n",
    "df_keywords = df_keywords.drop_duplicates(subset=[\"keyword_key\"])\n",
    "print(f\"DEDUPED KEYWORDS {len(df_keywords)}\")\n",
    "\n",
    "print(f\"STUDY KEYWORDS {len(df_study_keywords)}\")\n",
    "df_study_keywords = df_study_keywords.drop_duplicates(subset=[\"keyword_key\", \"study_key\"])\n",
    "print(f\"DEDUPED STUDY KEYWORDS {len(df_study_keywords)}\")\n",
    "print(\"----------------\")\n",
    "\n",
    "\n",
    "# duplicates = df_study_interventions[\n",
    "#     df_study_interventions.duplicated(subset=[\"intervention_key\", \"study_key\"], keep=False)\n",
    "# ].sort_values([\"study_key\", \"intervention_key\"])\n",
    "# print(df_study_interventions.groupby(['study_key', 'intervention_key']).size().sort_values(ascending=False).head(20))\n",
    "# print(duplicates.head(20))\n",
    "\n",
    "\n",
    "print(f\"INTERVENTIONS {len(df_interventions)}\")\n",
    "df_interventions = df_interventions.drop_duplicates(subset=[\"intervention_key\"])\n",
    "print(f\"DEDUPED INTERVENTIONS {len(df_interventions)}\")\n",
    "\n",
    "print(f\"STUDY INTERVENTIONS {len(df_study_interventions)}\")\n",
    "df_study_interventions = df_study_interventions.drop_duplicates(subset=[\"intervention_key\", \"study_key\"])\n",
    "print(f\"DEDUPED STUDY INTERVENTIONS {len(df_study_interventions)}\")\n",
    "print(\"----------------\")\n",
    "\n",
    "# duplicates = df_arm_group_interventions[\n",
    "#     df_arm_group_interventions.duplicated(subset=[\"arm_intervention_key\", \"study_key\", \"arm_intervention_name\"], keep=False)\n",
    "# ]\n",
    "# print(duplicates.head(20))\n",
    "\n",
    "\n",
    "print(f\"ARM GROUPS INTERVENTION {len(df_arm_group_interventions)}\")\n",
    "df_arm_group_interventions = df_arm_group_interventions.drop_duplicates(subset=[\"arm_intervention_key\", \"study_key\", \"arm_intervention_name\"])\n",
    "print(f\"DEDUPED ARM GROUPS INTERVENTION {len(df_arm_group_interventions)}\")\n",
    "print(\"----------------\")\n",
    "\n",
    "print(f\"LOCATIONS {len(df_locations)}\")\n",
    "df_locations = df_locations.drop_duplicates(subset=[\"location_key\"])\n",
    "print(f\" DEDUPED LOCATIONS {len(df_locations)}\")\n",
    "\n",
    "print(f\" STUDY LOCATIONS {len(df_study_locations)}\")\n",
    "df_study_locations = df_study_locations.drop_duplicates(subset=[\"location_key\", \"study_key\"])\n",
    "print(f\" DEDUPED STUDY LOCATIONS {len(df_study_locations)}\")\n",
    "print(\"----------------\")\n",
    "\n",
    "\n",
    "print(f\"CONTACTS {len(df_central_contacts)}\")\n",
    "df_central_contacts = df_central_contacts.drop_duplicates(subset=[\"contact_key\"])\n",
    "print(f\" DEDUPED CONTACTS {len(df_central_contacts)}\")\n",
    "\n",
    "print(f\"STUDY CONTACTS {len(df_study_central_contacts)}\")\n",
    "df_study_central_contacts = df_study_central_contacts.drop_duplicates(subset=[\"contact_key\", \"study_key\"])\n",
    "print(f\"DEDUPED STUDY CONTACTS {len(df_study_central_contacts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62006292-537f-4fd2-bb91-a55f8814bc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "studies.to_csv(\"data/study_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "c7406096-9193-4661-ac22-8c3076ea6bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sponsors.to_csv(\"data/sponsors.csv\", index=False)\n",
    "df_study_sponsors.to_csv(\"data/bridge_study_sponsors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "8c84996e-9e44-44a8-9d60-130e464daf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conditions.to_csv(\"data/conditions.csv\", index=False)\n",
    "df_study_conditions.to_csv(\"data/study_conditions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "3cec77e2-889c-456d-9d9b-815c6604cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords.to_csv(\"data/keywords.csv\", index=False)\n",
    "df_study_keywords.to_csv(\"data/study_keywords.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02c6e76b-aacb-4eac-8534-f9e97fbc75b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interventions.to_csv(\"data/interventions.csv\", index=False)\n",
    "df_study_interventions.to_csv(\"data/study_interventions.csv\", index=False)\n",
    "df_arm_group_interventions.to_csv(\"data/arm_groups_intrv.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ba2b6a64-dbaf-4eb2-aeae-b21415898eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_central_contacts.to_csv(\"data/contacts.csv\", index=False)\n",
    "df_study_central_contacts.to_csv(\"data/study_contacts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7e66f934-8584-4f2e-b8d0-337c754d48c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_study_locations.to_csv(\"data/study_locations.csv\", index=False)\n",
    "df_locations.to_csv(\"data/locations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f37e2-e57a-463c-abc3-aaab3782df8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
