{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41605e85-22b1-4de5-bb6b-d96a8c6fead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Any, Hashable, Tuple, Set\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from models import StudyResult\n",
    "from utils import generate_key\n",
    "from config import SCALAR_FIELDS, NON_SCALAR_FIELDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85279351-36d2-417b-b46f-0d67e394ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPECTED_TABLES = StudyResult.expected_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e41e822-caea-4899-be6f-112a424d11bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_study_file(file_loc: str) -> List[StudyResult]:\n",
    "\n",
    "    batch_results: List[StudyResult] = []\n",
    "    \n",
    "    df_studies = pd.read_parquet(file_loc)\n",
    "    df_studies = pd.json_normalize(df_studies[\"studies\"])\n",
    "    \n",
    "    for idx, study in df_studies.iterrows():\n",
    "        nct_index = SCALAR_FIELDS[\"nct_id\"]\n",
    "        nct_id = study.get(nct_index)\n",
    "    \n",
    "        if not nct_id:\n",
    "            continue\n",
    "    \n",
    "        try:\n",
    "            result = transform_single_study(nct_id, study)\n",
    "            batch_results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise\n",
    "    \n",
    "    return batch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7dd50957-070f-4b8e-8bf3-7cc77d721cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_batch_results(batch_results: List[StudyResult]) -> Dict[str, List[Dict]]:\n",
    "    \n",
    "    merged: Dict[str, List[Dict]] = defaultdict(list)\n",
    "    # print(f\" LEN BATCH BEFORE MERGE ---{len(batch_results)}\")\n",
    "    # print(f\" TYPE BATCH Before MERGE ---{type(batch_results)}\")\n",
    "\n",
    "    # print(type(batch_results[0].tables()))\n",
    "    # print(\"-----\")\n",
    "    print(f\"{type(batch_results)}\")\n",
    "    print(f\"{len(batch_results)}\")\n",
    "    for study_result in batch_results:\n",
    "        for table, rows in study_result.tables().items():\n",
    "            merged[table].extend(rows)\n",
    "\n",
    "    missing = set(EXPECTED_TABLES) - merged.keys()\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing tables: {missing}\")\n",
    "\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1d8657f-ee00-4ac2-9a49-15ed357bf55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_single_study(nct_id: str, study: pd.Series) -> StudyResult:\n",
    "  \n",
    "    study_key = generate_key(nct_id)\n",
    "    result = defaultdict(list)\n",
    "\n",
    "    # scalar fields\n",
    "    study_fields = transform_scalar_fields(study_key, study)\n",
    "    result[\"studies\"].append(study_fields)\n",
    "\n",
    "    # identificationModule\n",
    "    secondary_ids, nct_aliases = transform_identification_module(study_key, study)\n",
    "    result[\"secondary_ids\"].extend(secondary_ids)\n",
    "    result[\"nct_aliases\"].extend(nct_aliases)\n",
    "\n",
    "    # sponsorCollaboratorsModule\n",
    "    sponsor, study_sponsor, collaborators, study_collaborators = (\n",
    "        transform_sponsor_and_collaborators_module(nct_id, study_key, study)\n",
    "    )\n",
    "    result[\"sponsors\"].extend(sponsor)\n",
    "    result[\"study_sponsors\"].extend(study_sponsor)\n",
    "    result[\"collaborators\"].extend(collaborators)\n",
    "    result[\"study_collaborators\"].extend(study_collaborators)\n",
    "\n",
    "    # conditionsModule\n",
    "    conditions, study_conditions, keywords, study_keywords = (\n",
    "        transform_conditions_module(nct_id, study_key, study)\n",
    "    )\n",
    "    result[\"conditions\"].extend(conditions)\n",
    "    result[\"study_conditions\"].extend(study_conditions)\n",
    "    result[\"keywords\"].extend(keywords)\n",
    "    result[\"study_keywords\"].extend(study_keywords)\n",
    "\n",
    "    # armsInterventionsModule\n",
    "    (\n",
    "        arm_groups,\n",
    "        arm_interventions,\n",
    "        interventions,\n",
    "        study_interventions,\n",
    "        other_intervention_names,\n",
    "        study_intervention_aliases,\n",
    "    ) = transform_arms_interventions_module(study_key, study)\n",
    "    result[\"arm_groups\"].extend(arm_groups)\n",
    "    result[\"arm_interventions\"].extend(arm_interventions)\n",
    "    result[\"interventions\"].extend(interventions)\n",
    "    result[\"study_interventions\"].extend(study_interventions)\n",
    "    result[\"other_intervention_names\"].extend(other_intervention_names)\n",
    "    result[\"study_intervention_aliases\"].extend(study_intervention_aliases)\n",
    "\n",
    "    # outcomesModule\n",
    "    primary_outcomes, secondary_outcomes, other_outcomes = transform_outcomes_module(\n",
    "        study_key, study\n",
    "    )\n",
    "    result[\"primary_outcomes\"].extend(primary_outcomes)\n",
    "    result[\"secondary_outcomes\"].extend(secondary_outcomes)\n",
    "    result[\"other_outcomes\"].extend(other_outcomes)\n",
    "\n",
    "    # contactsLocationsModule\n",
    "    central_contacts, study_central_contacts, locations, study_locations = (\n",
    "        transform_contacts_location_module(study_key, study)\n",
    "    )\n",
    "    result[\"central_contacts\"].extend(central_contacts)\n",
    "    result[\"study_central_contacts\"].extend(study_central_contacts)\n",
    "    result[\"locations\"].extend(locations)\n",
    "    result[\"study_locations\"].extend(study_locations)\n",
    "\n",
    "    # referencesModule\n",
    "    references, link_references, ipd_references = transform_reference_module(\n",
    "        study_key, study\n",
    "    )\n",
    "    result[\"references\"].extend(references)\n",
    "    result[\"link_references\"].extend(link_references)\n",
    "    result[\"ipd_references\"].extend(ipd_references)\n",
    "\n",
    "    # outcomeMeasuresModule\n",
    "    (\n",
    "        outcome_measures,\n",
    "        outcome_measure_groups,\n",
    "        outcome_measure_denom_units,\n",
    "        outcome_measure_denom_counts,\n",
    "        outcome_measure_groups_result,\n",
    "        outcome_measure_analyses,\n",
    "        outcome_measure_comparison_groups,\n",
    "    ) = transform_outcome_measures_module(study_key, study)\n",
    "    result[\"outcome_measures\"].extend(outcome_measures)\n",
    "    result[\"outcome_measure_groups\"].extend(outcome_measure_groups)\n",
    "    result[\"outcome_measure_denom_units\"].extend(outcome_measure_denom_units)\n",
    "    result[\"outcome_measure_denom_counts\"].extend(outcome_measure_denom_counts)\n",
    "    result[\"outcome_measure_groups_result\"].extend(outcome_measure_groups_result)\n",
    "    result[\"outcome_measure_analyses\"].extend(outcome_measure_analyses)\n",
    "    result[\"outcome_measure_comparison_groups\"].extend(\n",
    "        outcome_measure_comparison_groups\n",
    "    )\n",
    "\n",
    "    # participantFlowModule\n",
    "    (\n",
    "        flow_groups,\n",
    "        flow_periods,\n",
    "        flow_period_milestones,\n",
    "        flow_period_milestone_achievements,\n",
    "        df_flow_period_withdrawals,\n",
    "        flow_period_withdrawal_reasons,\n",
    "    ) = transform_participant_flow_module(study_key, study)\n",
    "    result[\"flow_groups\"].extend(flow_groups)\n",
    "    result[\"flow_periods\"].extend(flow_periods)\n",
    "    result[\"flow_period_milestones\"].extend(flow_period_milestones)\n",
    "    result[\"flow_period_milestone_achievements\"].extend(\n",
    "        flow_period_milestone_achievements\n",
    "    )\n",
    "    result[\"df_flow_period_withdrawals\"].extend(df_flow_period_withdrawals)\n",
    "    result[\"flow_period_withdrawal_reasons\"].extend(flow_period_withdrawal_reasons)\n",
    "\n",
    "    # adverseEventsModule\n",
    "    (\n",
    "        adverse_events,\n",
    "        event_groups,\n",
    "        serious_events,\n",
    "        serious_event_stats,\n",
    "        other_events,\n",
    "        other_event_stats,\n",
    "    ) = transform_adverse_events_module(study_key, study)\n",
    "    result[\"adverse_events\"].extend(adverse_events)\n",
    "    result[\"event_groups\"].extend(event_groups)\n",
    "    result[\"serious_events\"].extend(serious_events)\n",
    "    result[\"serious_event_stats\"].extend(serious_event_stats)\n",
    "    result[\"other_events\"].extend(other_events)\n",
    "    result[\"other_event_stats\"].extend(other_event_stats)\n",
    "\n",
    "    # annotationModule\n",
    "    violations = transform_annotations_module(study_key, study)\n",
    "    result[\"violations\"].extend(violations)\n",
    "\n",
    "    # conditionBrowseModule\n",
    "    (\n",
    "        conditions_mesh,\n",
    "        study_conditions_mesh,\n",
    "        conditions_mesh_ancestors,\n",
    "        study_conditions_mesh_ancestors,\n",
    "        conditions_browse_leaves,\n",
    "        study_conditions_browse_leaves,\n",
    "        conditions_browse_branches,\n",
    "        study_conditions_browse_branches,\n",
    "    ) = transform_conditions_browse_module(study_key, study)\n",
    "\n",
    "    result[\"conditions_mesh\"].extend(conditions_mesh)\n",
    "    result[\"study_conditions_mesh\"].extend(study_conditions_mesh)\n",
    "    result[\"conditions_mesh_ancestors\"].extend(conditions_mesh_ancestors)\n",
    "    result[\"study_conditions_mesh_ancestors\"].extend(study_conditions_mesh_ancestors)\n",
    "    result[\"conditions_browse_leaves\"].extend(conditions_browse_leaves)\n",
    "    result[\"study_conditions_browse_leaves\"].extend(study_conditions_browse_leaves)\n",
    "    result[\"conditions_browse_branches\"].extend(conditions_browse_branches)\n",
    "    result[\"study_conditions_browse_branches\"].extend(study_conditions_browse_branches)\n",
    "\n",
    "    # interventionBrowseModule\n",
    "    (\n",
    "        interventions_mesh,\n",
    "        study_interventions_mesh,\n",
    "        interventions_mesh_ancestors,\n",
    "        study_interventions_mesh_ancestors,\n",
    "        interventions_browse_leaves,\n",
    "        study_interventions_browse_leaves,\n",
    "        interventions_browse_branches,\n",
    "        study_interventions_browse_branches,\n",
    "    ) = transform_interventions_browse_module(study_key, study)\n",
    "\n",
    "    result[\"interventions_mesh\"].extend(interventions_mesh)\n",
    "    result[\"study_interventions_mesh\"].extend(study_interventions_mesh)\n",
    "    result[\"interventions_mesh_ancestors\"].extend(interventions_mesh_ancestors)\n",
    "    result[\"study_interventions_mesh_ancestors\"].extend(\n",
    "        study_interventions_mesh_ancestors\n",
    "    )\n",
    "    result[\"interventions_browse_leaves\"].extend(interventions_browse_leaves)\n",
    "    result[\"study_interventions_browse_leaves\"].extend(\n",
    "        study_interventions_browse_leaves\n",
    "    )\n",
    "    result[\"interventions_browse_branches\"].extend(interventions_browse_branches)\n",
    "    result[\"study_interventions_browse_branches\"].extend(\n",
    "        study_interventions_browse_branches\n",
    "    )\n",
    "\n",
    "    return StudyResult(\n",
    "        studies=result[\"studies\"],\n",
    "        secondary_ids=result[\"secondary_ids\"],\n",
    "        nct_aliases=result[\"nct_aliases\"],\n",
    "        sponsors=result[\"sponsors\"],\n",
    "        study_sponsors=result[\"study_sponsors\"],\n",
    "        collaborators=result[\"collaborators\"],\n",
    "        study_collaborators=result[\"study_collaborators\"],\n",
    "        conditions=result[\"conditions\"],\n",
    "        study_conditions=result[\"study_conditions\"],\n",
    "        keywords=result[\"keywords\"],\n",
    "        study_keywords=result[\"study_keywords\"],\n",
    "        arm_groups=result[\"arm_groups\"],\n",
    "        arm_interventions=result[\"arm_interventions\"],\n",
    "        interventions=result[\"interventions\"],\n",
    "        study_interventions=result[\"study_interventions\"],\n",
    "        other_intervention_names=result[\"other_intervention_names\"],\n",
    "        study_intervention_aliases=result[\"study_intervention_aliases\"],\n",
    "        primary_outcomes=result[\"primary_outcomes\"],\n",
    "        secondary_outcomes=result[\"secondary_outcomes\"],\n",
    "        other_outcomes=result[\"other_outcomes\"],\n",
    "        central_contacts=result[\"central_contacts\"],\n",
    "        study_central_contacts=result[\"study_central_contacts\"],\n",
    "        locations=result[\"locations\"],\n",
    "        study_locations=result[\"study_locations\"],\n",
    "        references=result[\"references\"],\n",
    "        link_references=result[\"link_references\"],\n",
    "        ipd_references=result[\"ipd_references\"],\n",
    "        outcome_measures=result[\"outcome_measures\"],\n",
    "        outcome_measure_groups=result[\"outcome_measure_groups\"],\n",
    "        outcome_measure_denom_units=result[\"outcome_measure_denom_units\"],\n",
    "        outcome_measure_denom_counts=result[\"outcome_measure_denom_counts\"],\n",
    "        outcome_measure_groups_result=result[\"outcome_measure_groups_result\"],\n",
    "        outcome_measure_analyses=result[\"outcome_measure_analyses\"],\n",
    "        outcome_measure_comparison_groups=result[\"outcome_measure_comparison_groups\"],\n",
    "        flow_groups=result[\"flow_groups\"],\n",
    "        flow_periods=result[\"flow_periods\"],\n",
    "        flow_period_milestones=result[\"flow_period_milestones\"],\n",
    "        flow_period_milestone_achievements=result[\"flow_period_milestone_achievements\"],\n",
    "        df_flow_period_withdrawals=result[\"df_flow_period_withdrawals\"],\n",
    "        flow_period_withdrawal_reasons=result[\"flow_period_withdrawal_reasons\"],\n",
    "        adverse_events=result[\"adverse_events\"],\n",
    "        event_groups=result[\"event_groups\"],\n",
    "        serious_events=result[\"serious_events\"],\n",
    "        serious_event_stats=result[\"serious_event_stats\"],\n",
    "        other_events=result[\"other_events\"],\n",
    "        other_event_stats=result[\"other_event_stats\"],\n",
    "        violations=result[\"violations\"],\n",
    "        conditions_mesh=result[\"conditions_mesh\"],\n",
    "        study_conditions_mesh=result[\"study_conditions_mesh\"],\n",
    "        conditions_mesh_ancestors=result[\"conditions_mesh_ancestors\"],\n",
    "        study_conditions_mesh_ancestors=result[\"study_conditions_mesh_ancestors\"],\n",
    "        conditions_browse_leaves=result[\"conditions_browse_leaves\"],\n",
    "        study_conditions_browse_leaves=result[\"study_conditions_browse_leaves\"],\n",
    "        conditions_browse_branches=result[\"conditions_browse_branches\"],\n",
    "        study_conditions_browse_branches=result[\"study_conditions_browse_branches\"],\n",
    "        interventions_mesh=result[\"interventions_mesh\"],\n",
    "        study_interventions_mesh=result[\"study_interventions_mesh\"],\n",
    "        interventions_mesh_ancestors=result[\"interventions_mesh_ancestors\"],\n",
    "        study_interventions_mesh_ancestors=result[\"study_interventions_mesh_ancestors\"],\n",
    "        interventions_browse_leaves=result[\"interventions_browse_leaves\"],\n",
    "        study_interventions_browse_leaves=result[\"study_interventions_browse_leaves\"],\n",
    "        interventions_browse_branches=result[\"interventions_browse_branches\"],\n",
    "        study_interventions_browse_branches=result[\n",
    "            \"study_interventions_browse_branches\"\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97b02719-e323-4da3-a50d-d598096f4787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_scalar_fields(study_key: str, study_data: pd.Series) -> Dict:\n",
    "    study_record = dict()\n",
    "\n",
    "    study_record[\"study_key\"] = study_key\n",
    "    for entity_key in SCALAR_FIELDS:\n",
    "        index_field = SCALAR_FIELDS.get(entity_key)\n",
    "\n",
    "        study_record[entity_key] = study_data.get(index_field)\n",
    "\n",
    "    return study_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34399577-7982-458e-b646-eb6bf1c27d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_identification_module(study_key: str, study_data: pd.Series) -> Tuple:\n",
    "    secondary_ids = []\n",
    "    nct_aliases = []\n",
    "\n",
    "    identification_index = NON_SCALAR_FIELDS[\"identification\"][\"index_field\"]\n",
    "\n",
    "    # Secondary id infos\n",
    "    secondary_id_infos = study_data.get(f\"{identification_index}.secondaryIdInfos\")\n",
    "\n",
    "    if (\n",
    "        isinstance(secondary_id_infos, (list, np.ndarray))\n",
    "        and len(secondary_id_infos) > 0\n",
    "    ):\n",
    "        for secondary_id_info in secondary_id_infos:\n",
    "            secondary_id = secondary_id_info.get(\"id\")\n",
    "            secondary_id_key = generate_key(study_key, secondary_id)\n",
    "\n",
    "            secondary_ids.append(\n",
    "                {\n",
    "                    \"secondary_id_key\": secondary_id_key,\n",
    "                    \"study_key\": study_key,\n",
    "                    \"id\": secondary_id,\n",
    "                    \"type\": secondary_id_info.get(\"type\"),\n",
    "                    \"domain\": secondary_id_info.get(\"domain\"),\n",
    "                    \"link\": secondary_id_info.get(\"link\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # nct id aliases\n",
    "    nct_id_aliases = study_data.get(f\"{identification_index}.nctIdAliases\")\n",
    "\n",
    "    if isinstance(nct_id_aliases, (list, np.ndarray)) and len(nct_id_aliases) > 0:\n",
    "        for nct_id_alias in nct_id_aliases:\n",
    "            nct_aliases.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"id_alias\": nct_id_alias,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return secondary_ids, nct_aliases\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4aaa8548-258d-4db9-bb04-114006872a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_sponsor_and_collaborators_module(\n",
    "    nct_id: str, study_key: str, study_data: pd.Series\n",
    ") -> Tuple:\n",
    "    sponsor = []\n",
    "    study_sponsor = []\n",
    "    collaborators = []\n",
    "    study_collaborators = []\n",
    "\n",
    "    sponsor_collaborator_index = NON_SCALAR_FIELDS[\"sponsor_collaborators\"][\n",
    "        \"index_field\"\n",
    "    ]\n",
    "\n",
    "    ## sponsor name and class are scalar values and MUST be transformed as so\n",
    "    lead_sponsor_name = study_data.get(f\"{sponsor_collaborator_index}.leadSponsor.name\")\n",
    "    lead_sponsor_class = study_data.get(\n",
    "        f\"{sponsor_collaborator_index}.leadSponsor.class\"\n",
    "    )\n",
    "\n",
    "    if pd.notna(lead_sponsor_name) and pd.notna(lead_sponsor_class):\n",
    "\n",
    "        sponsor_key = generate_key(lead_sponsor_name, lead_sponsor_class)\n",
    "        sponsor.append(\n",
    "            {\n",
    "                \"sponsor_key\": sponsor_key,\n",
    "                \"name\": lead_sponsor_name,\n",
    "                \"sponsor_class\": lead_sponsor_class,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        study_sponsor.append({\"study_key\": study_key, \"sponsor_key\": sponsor_key})\n",
    "\n",
    "    # collaborators\n",
    "    collaborators_list = study_data.get(\n",
    "        f\"{sponsor_collaborator_index}.collaborators\"\n",
    "    )\n",
    "\n",
    "    if (\n",
    "        isinstance(collaborators_list, (list, np.ndarray))\n",
    "        and len(collaborators_list) > 0\n",
    "    ):\n",
    "        for collaborator in collaborators_list:\n",
    "            collaborator_key = generate_key(\n",
    "                collaborator.get(\"name\"), collaborator.get(\"class\")\n",
    "            )\n",
    "\n",
    "            collaborators.append(\n",
    "                {\n",
    "                    \"collaborator_key\": collaborator_key,\n",
    "                    \"name\": collaborator.get(\"name\"),\n",
    "                    \"collaborator_class\": collaborator.get(\"class\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            study_collaborators.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"collaborator_key\": collaborator_key,\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "    return sponsor, study_sponsor, collaborators, study_collaborators\n",
    "\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7c7bfba-58b1-4e0a-9e50-456d8088851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_conditions_module(\n",
    "    nct_id: str, study_key: str, study_data: pd.Series\n",
    ") -> Tuple:\n",
    "    \n",
    "    conditions = []\n",
    "    study_conditions = []\n",
    "    keywords = []\n",
    "    study_keywords = []\n",
    "\n",
    "    conditions_index = NON_SCALAR_FIELDS[\"conditions\"][\"index_field\"]\n",
    "\n",
    "    conditions_list = study_data.get(f\"{conditions_index}.conditions\")\n",
    "\n",
    "    if isinstance(conditions_list, (list, np.ndarray)) and len(conditions_list) > 0:\n",
    "        for condition in conditions_list:\n",
    "            condition_key = generate_key(condition)\n",
    "\n",
    "            conditions.append(\n",
    "                {\"condition_key\": condition_key, \"condition_name\": condition.lower()}\n",
    "            )\n",
    "\n",
    "            study_conditions.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"condition_key\": condition_key,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    keywords_list = study_data.get(f\"{conditions_index}.keywords\")\n",
    "\n",
    "    if isinstance(keywords_list, (list, np.ndarray)) and len(keywords_list) > 0:\n",
    "\n",
    "        for keyword in keywords_list:\n",
    "            keyword_key = generate_key(keyword)\n",
    "\n",
    "            keywords.append({\"keyword_key\": keyword_key, \"keyword_name\": keyword.lower()})\n",
    "\n",
    "            study_keywords.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"keyword_key\": keyword_key,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return conditions, study_conditions, keywords, study_keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8603702-1d62-4e9c-9105-8327d8b95461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ALIASES = {\n",
    "    \"sham\": \"Placebo\",\n",
    "    \"5-fu\": \"Fluorouracil\",\n",
    "    \"5-fluorouracil\": \"Fluorouracil\",\n",
    "    \"trastuzumab emtansine\": \"Trastuzumab\",\n",
    "    \"t-dm1\": \"Trastuzumab\",\n",
    "}\n",
    "\n",
    "\n",
    "ARMS_SOURCE = \"ARM\"\n",
    "\n",
    "\n",
    "def standardize_intervention_name(\n",
    "    intervention_name: str, source: str | None = None\n",
    ") -> str | None:\n",
    "    # Manual cleaning is not enough to handle randomness and unpredictability of the intervention names\n",
    "    # as they're entered manually without validation on the API therefore:\n",
    "    # MeSH terms are more reliable for queries but intervention names takes precedence over mesh during\n",
    "    # API search as they're more specific and layman friendly\n",
    "\n",
    "    if not intervention_name:\n",
    "        return None\n",
    "\n",
    "    if source == ARMS_SOURCE:\n",
    "        # armGroups[].interventionNames uses format \"Type: Name\" (e.g., \"Drug: Cisplatin\")\n",
    "        # interventions[].name uses just \"Name\" (e.g., \"Cisplatin\")\n",
    "        # Stripping prefix is necessary to enable joining arm_interventions -> interventions\n",
    "\n",
    "        parts = intervention_name.split(\": \", 1)\n",
    "        intervention_name = parts[1] if len(parts) > 1 else intervention_name\n",
    "\n",
    "    cleaned = intervention_name.lower().strip()\n",
    "    if cleaned in ALIASES:\n",
    "        return ALIASES[cleaned]\n",
    "\n",
    "    if cleaned.startswith(\"placebo\"):\n",
    "        # extensive descriptions of placebo arms e.g 'Placebo matched to M2951'\n",
    "        # should only be in the description field in arms_intervention list\n",
    "        return \"Placebo\"\n",
    "\n",
    "    words = intervention_name.strip().split()\n",
    "    return \" \".join([w if w.isupper() else w.capitalize() for w in words])\n",
    "\n",
    "\n",
    "def transform_arms_interventions_module(study_key: str, study_data: pd.Series) -> Tuple:\n",
    "\n",
    "    arm_groups = []\n",
    "    arm_interventions = []\n",
    "\n",
    "    interventions = []\n",
    "    study_interventions = []\n",
    "    other_intervention_names = []\n",
    "    study_intervention_aliases = []\n",
    "\n",
    "    arms_interventions_index = NON_SCALAR_FIELDS[\"arms_interventions\"][\"index_field\"]\n",
    "    arm_groups_list = study_data.get(f\"{arms_interventions_index}.armGroups\")\n",
    "\n",
    "    if isinstance(arm_groups_list, (list, np.ndarray)) and len(arm_groups_list) > 0:\n",
    "        for arm_group in arm_groups_list:\n",
    "            arm_label = arm_group.get(\"label\")\n",
    "            arm_description = arm_group.get(\"description\")\n",
    "            arm_type = arm_group.get(\"type\")\n",
    "\n",
    "            arm_group_key = generate_key(\n",
    "                study_key, arm_label, arm_description, arm_type\n",
    "            )\n",
    "\n",
    "            arm_groups.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"arm_group_key\": arm_group_key,\n",
    "                    \"arm_label\": arm_label,\n",
    "                    \"arm_description\": arm_description,\n",
    "                    \"arm_type\": arm_type,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            arm_interventions_list = arm_group.get(\"interventionNames\")\n",
    "            if (\n",
    "                isinstance(arm_interventions_list, (list, np.ndarray))\n",
    "                and len(arm_interventions_list) > 0\n",
    "            ):\n",
    "\n",
    "                for arm_intervention in arm_interventions_list:\n",
    "                    arm_intervention_name = standardize_intervention_name(\n",
    "                        arm_intervention, ARMS_SOURCE\n",
    "                    )\n",
    "                    arm_intervention_key = generate_key(arm_intervention_name)\n",
    "\n",
    "                    arm_interventions.append(\n",
    "                        {\n",
    "                            \"study_key\": study_key,\n",
    "                            \"arm_group_key\": arm_group_key,\n",
    "                            \"arm_intervention_key\": arm_intervention_key,\n",
    "                            \"arm_intervention_name\": arm_intervention_name,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    interventions_list = study_data.get(f\"{arms_interventions_index}.interventions\")\n",
    "    if (\n",
    "        isinstance(interventions_list, (list, np.ndarray))\n",
    "        and len(interventions_list) > 0\n",
    "    ):\n",
    "        for intervention in interventions_list:\n",
    "            main_name = standardize_intervention_name(intervention.get(\"name\"))\n",
    "            intervention_type = intervention.get(\"type\")\n",
    "\n",
    "            intervention_key = generate_key(\n",
    "                main_name\n",
    "            )  # Only name is used to enable matching on both arms and interventions\n",
    "\n",
    "            interventions.append(\n",
    "                {\n",
    "                    \"intervention_key\": intervention_key,\n",
    "                    \"intervention_name\": main_name,\n",
    "                    \"intervention_type\": intervention_type,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            study_interventions.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"intervention_key\": intervention_key,\n",
    "                    \"description\": intervention.get(\"description\"),\n",
    "                    \"is_primary_name\": True,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            other_names = intervention.get(\"otherNames\")\n",
    "\n",
    "            if isinstance(other_names, (list, np.ndarray)) and len(other_names) > 0:\n",
    "                for other_name in other_names:\n",
    "                    other_name = standardize_intervention_name(other_name)\n",
    "                    if other_name == main_name:\n",
    "                        continue  # some studies put the main name in the list of other names\n",
    "\n",
    "                    other_intervention_key = generate_key(other_name)\n",
    "                    other_intervention_names.append(\n",
    "                        {\n",
    "                            \"intervention_key\": other_intervention_key,\n",
    "                            # has its own key as other here could be main and vice versa in other studies.\n",
    "                            # and it remains independent in the warehouse\n",
    "                            \"intervention_name\": other_name,\n",
    "                            \"intervention_type\": intervention_type,  # inherit from parent\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    study_intervention_aliases.append(\n",
    "                        {\n",
    "                            \"study_key\": study_key,\n",
    "                            \"intervention_key\": other_intervention_key,\n",
    "                            \"description\": intervention.get(\"description\"),\n",
    "                            \"is_primary_name\": False,\n",
    "                        }\n",
    "                    )\n",
    "            # armGroupLabels is excluded to avoid bi-directional inconsistencies due to human errors from source.\n",
    "            # check documentation/excluded_fields.md for details\n",
    "\n",
    "    return (\n",
    "        arm_groups,\n",
    "        arm_interventions,\n",
    "        interventions,\n",
    "        study_interventions,\n",
    "        other_intervention_names,\n",
    "        study_intervention_aliases,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aaada7de-b488-4950-9723-9fa252e91c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_outcomes_module(study_key: str, study_data: pd.Series) -> Tuple:\n",
    " \n",
    "    primary_outcomes = []\n",
    "    secondary_outcomes = []\n",
    "    other_outcomes = []\n",
    "\n",
    "    outcomes_module_index = NON_SCALAR_FIELDS[\"outcomes\"][\"index_field\"]\n",
    "\n",
    "    primary_outcomes_list = study_data.get(f\"{outcomes_module_index}.primaryOutcomes\")\n",
    "\n",
    "    if (\n",
    "        isinstance(primary_outcomes_list, (list, np.ndarray))\n",
    "        and len(primary_outcomes_list) > 0\n",
    "    ):\n",
    "        for primary_outcome in primary_outcomes_list:\n",
    "            outcome_measure = primary_outcome.get(\"measure\")\n",
    "            outcome_description = primary_outcome.get(\"description\")\n",
    "            outcome_timeframe = primary_outcome.get(\"timeFrame\")\n",
    "            \n",
    "            outcome_key = generate_key(study_key, outcome_measure, outcome_description, outcome_timeframe)\n",
    "\n",
    "            primary_outcomes.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"outcome_key\": outcome_key,\n",
    "                    \"measure\": outcome_measure,\n",
    "                    \"description\": outcome_description,\n",
    "                    \"time_frame\": outcome_timeframe,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    secondary_outcomes_list = study_data.get(\n",
    "        f\"{outcomes_module_index}.secondaryOutcomes\"\n",
    "    )\n",
    "    if (\n",
    "        isinstance(secondary_outcomes_list, (list, np.ndarray))\n",
    "        and len(secondary_outcomes_list) > 0\n",
    "    ):\n",
    "        for secondary_outcome in secondary_outcomes_list:\n",
    "            outcome_measure = secondary_outcome.get(\"measure\")\n",
    "            outcome_description = secondary_outcome.get(\"description\")\n",
    "            outcome_timeframe = secondary_outcome.get(\"timeFrame\")\n",
    "            \n",
    "            outcome_key = generate_key(study_key, outcome_measure, outcome_description, outcome_timeframe)\n",
    "\n",
    "            secondary_outcomes.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"outcome_key\": outcome_key,\n",
    "                    \"measure\": outcome_measure,\n",
    "                    \"description\": outcome_description,\n",
    "                    \"time_frame\": outcome_timeframe,\n",
    "                }\n",
    "            )\n",
    "            \n",
    "\n",
    "    other_outcomes_list = study_data.get(f\"{outcomes_module_index}.otherOutcomes\")\n",
    "    if (\n",
    "        isinstance(other_outcomes_list, (list, np.ndarray))\n",
    "        and len(other_outcomes_list) > 0\n",
    "    ):\n",
    "        for other_outcome in other_outcomes_list:\n",
    "            outcome_measure = other_outcome.get(\"measure\")\n",
    "            outcome_description = other_outcome.get(\"description\")\n",
    "            outcome_timeframe = other_outcome.get(\"timeFrame\")\n",
    "\n",
    "            outcome_key = generate_key(study_key, outcome_measure, outcome_description, outcome_timeframe)\n",
    "\n",
    "            other_outcomes.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"outcome_key\": outcome_key,\n",
    "                    \"measure\": outcome_measure,\n",
    "                    \"description\": outcome_description,\n",
    "                    \"time_frame\": outcome_timeframe,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return primary_outcomes, secondary_outcomes, other_outcomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bffb094e-486c-435d-895b-ed871317473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_contacts_location_module(study_key: str, study_data: pd.Series) -> Tuple:\n",
    "    central_contacts = []\n",
    "    study_central_contacts = []\n",
    "    locations = []\n",
    "    study_locations = []\n",
    "\n",
    "    contacts_locations_index = NON_SCALAR_FIELDS[\"contacts_location\"][\"index_field\"]\n",
    "\n",
    "    #contacts\n",
    "    central_contacts_list = study_data.get(f\"{contacts_locations_index}.centralContacts\")\n",
    "\n",
    "\n",
    "    if (\n",
    "        isinstance(central_contacts_list, (list, np.ndarray))\n",
    "        and len(central_contacts_list) > 0\n",
    "    ):\n",
    "\n",
    "        for central_contact in central_contacts_list:\n",
    "            name = central_contact.get(\"name\")\n",
    "            role = central_contact.get(\"role\")\n",
    "            phone = central_contact.get(\"phone\")\n",
    "            email = central_contact.get(\"email\")\n",
    "\n",
    "            central_contact_key = generate_key(name, role, phone, email)\n",
    "\n",
    "            central_contacts.append(\n",
    "                {\n",
    "                    \"contact_key\": central_contact_key,\n",
    "                    \"name\": name,\n",
    "                    \"role\": role,\n",
    "                    \"phone\": phone,\n",
    "                    \"email\": email,\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            study_central_contacts.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"contact_key\": central_contact_key,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    #locations\n",
    "    locations_list = study_data.get(f\"{contacts_locations_index}.locations\")\n",
    "\n",
    "    if isinstance(locations_list, (list, np.ndarray)) and len(locations_list) > 0:\n",
    "        for location in locations_list:\n",
    "            facility = location.get(\"facility\")\n",
    "            city = location.get(\"city\")\n",
    "            state = location.get(\"state\")\n",
    "            country = location.get(\"country\")\n",
    "\n",
    "            location_key = generate_key(facility, city, state, country)\n",
    "            curr_location = {\n",
    "                \"location_key\": location_key,\n",
    "                \"facility\": facility,\n",
    "                \"city\": city,\n",
    "                \"state\": state,\n",
    "                \"country\": country\n",
    "            }\n",
    "            geopoint = location.get(\"geoPoint\")\n",
    "\n",
    "            if isinstance(geopoint, dict) and geopoint:\n",
    "                curr_location[\"lat\"] = (\n",
    "                    float(geopoint.get(\"lat\")) if geopoint.get(\"lat\") else None\n",
    "                )\n",
    "                curr_location[\"lon\"] = (\n",
    "                    float(geopoint.get(\"lon\")) if geopoint.get(\"lon\") else None\n",
    "                )\n",
    "\n",
    "            locations.append(curr_location)\n",
    "\n",
    "            study_locations.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"location_key\": location_key,\n",
    "                    \"status\": location.get(\"status\"),\n",
    "                    \"contacts\": location.get(\"contacts\"), #json blob\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return central_contacts, study_central_contacts, locations, study_locations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e663806a-0162-440a-a9c7-6d28cdcd3a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def transform_reference_module(study_key: str, study_data: pd.Series) -> Tuple:\n",
    "    study_references = []\n",
    "    link_references = []\n",
    "    ipd_references = []\n",
    "\n",
    "    references_index = NON_SCALAR_FIELDS[\"references\"][\"index_field\"]\n",
    "\n",
    "    references_list = study_data.get(f\"{references_index}.references\")\n",
    "\n",
    "    if isinstance(references_list, (list, np.ndarray)) and len(references_list) > 0:\n",
    "\n",
    "        for reference in references_list:\n",
    "            pmid = reference.get(\"pmid\")\n",
    "            reference_key = generate_key(study_key, pmid)\n",
    "            study_references.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"ref_key\": reference_key,\n",
    "                    \"pmid\": pmid,\n",
    "                    \"type\": reference.get(\"type\"),\n",
    "                    \"citation\": reference.get(\"citation\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    links_list = study_data.get(f\"{references_index}.seeAlsoLinks\")\n",
    "    if isinstance(links_list, (list, np.ndarray)) and len(links_list) > 0:\n",
    "\n",
    "        for link in links_list:\n",
    "            label = link.get(\"label\")\n",
    "            url = link.get(\"url\")\n",
    "            link_key = generate_key(study_key, label, url)\n",
    "            link_references.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"link_key\": link_key,\n",
    "                    \"label\": label,\n",
    "                    \"url\": url\n",
    "                }\n",
    "            )\n",
    "\n",
    "    ipds_list = study_data.get(f\"{references_index}.availIpds\")\n",
    "\n",
    "    if isinstance(ipds_list, (list, np.ndarray)) and len(ipds_list) > 0:\n",
    "\n",
    "        for ipd in ipds_list:\n",
    "            ipd_id = ipd.get(\"id\")\n",
    "            ipd_type = ipd.get(\"type\")\n",
    "            ipd_url = ipd.get(\"url\")\n",
    "\n",
    "            ipd_key = generate_key(study_key, ipd_id, ipd_type, ipd_url)\n",
    "            ipd_references.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"ipd_key\": ipd_key,\n",
    "                    \"id\": ipd_id,\n",
    "                    \"type\": ipd_type,\n",
    "                    \"url\": ipd_url,\n",
    "                    \"comment\": ipd.get(\"comment\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return study_references, link_references, ipd_references\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d9baafa-97b3-44a0-92bd-d68d10b32fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def transform_outcome_measures_module(study_key: str, study_data: pd.Series) -> Tuple:\n",
    "    outcome_measures = []\n",
    "    outcome_measure_groups = []\n",
    "    outcome_measure_denom_units = []\n",
    "    outcome_measure_denom_counts = []\n",
    "    outcome_measure_groups_result = []\n",
    "    outcome_measure_analyses = []\n",
    "    outcome_measure_comparison_groups = []\n",
    "\n",
    "    outcomes_index = NON_SCALAR_FIELDS[\"outcome_measures\"][\"index_field\"]\n",
    "    outcomes_measures_list = study_data.get(f\"{outcomes_index}.outcomeMeasures\")\n",
    "\n",
    "    if (\n",
    "        isinstance(outcomes_measures_list, (list, np.ndarray))\n",
    "        and len(outcomes_measures_list) > 0\n",
    "    ):\n",
    "        for outcome_measure in outcomes_measures_list:\n",
    "            outcome_measure_title = outcome_measure.get(\"title\")\n",
    "            outcome_measure_type = outcome_measure.get(\"type\")\n",
    "            outcome_measure_key = generate_key(\n",
    "                study_key, outcome_measure_title, outcome_measure_type\n",
    "            )\n",
    "\n",
    "            outcome_measures.append(\n",
    "                {\n",
    "                    \"outcome_measure_key\": outcome_measure_key,\n",
    "                    \"study_key\": study_key,\n",
    "                    \"outcome_type\": outcome_measure_type,\n",
    "                    \"title\": outcome_measure_title,\n",
    "                    \"description\": outcome_measure.get(\"description\"),\n",
    "                    \"population_description\": outcome_measure.get(\n",
    "                        \"populationDescription\"\n",
    "                    ),\n",
    "                    \"reporting_status\": outcome_measure.get(\"reportingStatus\"),\n",
    "                    \"anticipated_posting_date\": outcome_measure.get(\n",
    "                        \"anticipatedPostingDate\"\n",
    "                    ),\n",
    "                    \"param_type\": outcome_measure.get(\"paramType\"),\n",
    "                    \"dispersion_type\": outcome_measure.get(\"dispersionType\"),\n",
    "                    \"unit_of_measure\": outcome_measure.get(\"unitOfMeasure\"),\n",
    "                    \"calculate_pct\": outcome_measure.get(\"calculatePct\"),\n",
    "                    \"time_frame\": outcome_measure.get(\"timeFrame\"),\n",
    "                    \"denom_units_selected\": outcome_measure.get(\"denomUnitsSelected\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            groups = outcome_measure.get(\"groups\")\n",
    "            if isinstance(groups, (list, np.ndarray)) and len(groups) > 0:\n",
    "                for group in groups:\n",
    "                    group_id = group.get(\"id\")\n",
    "                    outcome_group_key = generate_key(\n",
    "                        study_key, outcome_measure_key, group_id\n",
    "                    )\n",
    "\n",
    "                    outcome_measure_groups.append(\n",
    "                        {\n",
    "                            \"group_key\": outcome_group_key,\n",
    "                            \"study_key\": study_key,\n",
    "                            \"outcome_measure_key\": outcome_measure_key,\n",
    "                            \"group_id\": group_id,\n",
    "                            \"title\": group.get(\"title\"),\n",
    "                            \"description\": group.get(\"description\"),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "            denoms_list = outcome_measure.get(\"denoms\")\n",
    "            if isinstance(denoms_list, (list, np.ndarray)) and len(denoms_list) > 0:\n",
    "                for denom in denoms_list:\n",
    "                    denom_unit = denom.get(\"units\")\n",
    "                    denom_unit = denom_unit.upper() if denom_unit else \"UNKNOWN\"\n",
    "                    denom_unit_key = generate_key(denom_unit)\n",
    "\n",
    "                    outcome_measure_denom_units.append(\n",
    "                        {\n",
    "                            \"denom_unit_key\": denom_unit_key,\n",
    "                            \"denom_unit\": denom_unit,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    denom_counts = denom.get(\"counts\")\n",
    "                    if (\n",
    "                        isinstance(denom_counts, (list, np.ndarray))\n",
    "                        and len(denom_counts) > 0\n",
    "                    ):\n",
    "                        for denom_count in denom_counts:\n",
    "                            denom_count_group_id = denom_count.get(\"groupId\")\n",
    "                            denom_count_group_key = generate_key(\n",
    "                                study_key, outcome_measure_key, denom_count_group_id\n",
    "                            )\n",
    "                            denom_count_key = generate_key(\n",
    "                                study_key,\n",
    "                                outcome_measure_key,\n",
    "                                denom_unit_key,\n",
    "                                denom_count_group_id,\n",
    "                            )\n",
    "\n",
    "                            outcome_measure_denom_counts.append(\n",
    "                                {\n",
    "                                    \"denom_count_key\": denom_count_key,\n",
    "                                    \"study_key\": study_key,\n",
    "                                    \"outcome_measure_key\": outcome_measure_key,\n",
    "                                    \"denom_unit_key\": denom_unit_key,\n",
    "                                    \"group_key\": denom_count_group_key,\n",
    "                                    \"group_id\": denom_count_group_id,\n",
    "                                    \"denom_value\": denom_count.get(\"value\"),\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "            classes = outcome_measure.get(\"classes\")\n",
    "            if isinstance(classes, (list, np.ndarray)) and len(classes) > 0:\n",
    "                for single_class in classes:\n",
    "                    # class is not a true container and only wraps categories contrary to what the docs say\n",
    "                    categories = single_class.get(\"categories\")\n",
    "\n",
    "                    if (\n",
    "                        isinstance(categories, (list, np.ndarray))\n",
    "                        and len(categories) > 0\n",
    "                    ):\n",
    "                        for cat_idx, category in enumerate(categories):\n",
    "                            measurements = category.get(\"measurements\")\n",
    "                            if (\n",
    "                                isinstance(measurements, (list, np.ndarray))\n",
    "                                and len(measurements) > 0\n",
    "                            ):\n",
    "                                for measurement in measurements:\n",
    "                                    meas_group_id = measurement.get(\"groupId\")\n",
    "                                    meas_group_key = generate_key(\n",
    "                                        study_key, outcome_measure_key, meas_group_id\n",
    "                                    )  # group keys must be created the same way\n",
    "\n",
    "                                    outcome_measure_groups_result.append(\n",
    "                                        {\n",
    "                                            \"group_key\": meas_group_key,\n",
    "                                            \"outcome_measure_key\": outcome_measure_key,\n",
    "                                            \"study_key\": study_key,\n",
    "                                            \"group_id\": meas_group_id,\n",
    "                                            \"value\": measurement.get(\"value\"),\n",
    "                                            \"lower_limit\": measurement.get(\n",
    "                                                \"lowerLimit\"\n",
    "                                            ),\n",
    "                                            \"upper_limit\": measurement.get(\n",
    "                                                \"upperLimit\"\n",
    "                                            ),\n",
    "                                            \"spread\": measurement.get(\"spread\"),\n",
    "                                            \"comment\": measurement.get(\"comment\"),\n",
    "                                        }\n",
    "                                    )\n",
    "\n",
    "            analyses = outcome_measure.get(\"analyses\")\n",
    "            if isinstance(analyses, (list, np.ndarray)) and len(analyses) > 0:\n",
    "                for analysis in analyses:\n",
    "                    param_type = analysis.get(\"paramType\")\n",
    "                    param_value = analysis.get(\"paramValue\")\n",
    "\n",
    "                    analysis_key = generate_key(\n",
    "                        study_key, outcome_measure_key, param_type, param_value\n",
    "                    )\n",
    "\n",
    "                    outcome_measure_analyses.append(\n",
    "                        {\n",
    "                            \"analysis_key\": analysis_key,\n",
    "                            \"study_key\": study_key,\n",
    "                            \"outcome_measure_key\": outcome_measure_key,\n",
    "                            \"param_type\": param_type,\n",
    "                            \"param_value\": param_value,\n",
    "                            \"dispersion_type\": analysis.get(\"dispersionType\"),\n",
    "                            \"dispersion_value\": analysis.get(\"dispersionValue\"),\n",
    "                            \"statistical_method\": analysis.get(\"statisticalMethod\"),\n",
    "                            \"statistical_comment\": analysis.get(\"statisticalComment\"),\n",
    "                            \"p_value\": analysis.get(\"pValue\"),\n",
    "                            \"p_value_comment\": analysis.get(\"pValueComment\"),\n",
    "                            \"non_inferiority_type\": analysis.get(\"nonInferiorityType\"),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    analysis_comparison_groups = analysis.get(\"groupIds\")\n",
    "                    if (\n",
    "                        isinstance(analysis_comparison_groups, (list, np.ndarray))\n",
    "                        and len(analysis_comparison_groups) > 0\n",
    "                    ):\n",
    "                        for group_id in analysis_comparison_groups:\n",
    "                            group_key = generate_key(\n",
    "                                study_key, outcome_measure_key, group_id\n",
    "                            )\n",
    "                            outcome_measure_comparison_groups.append(\n",
    "                                {   \"study_key\": study_key,\n",
    "                                    \"outcome_measure_key\": outcome_measure_key,\n",
    "                                    \"analysis_key\": analysis_key,\n",
    "                                    \"group_key\": group_key,\n",
    "                                    \"group_id\": group_id,\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "    return (\n",
    "        outcome_measures,\n",
    "        outcome_measure_groups,\n",
    "        outcome_measure_denom_units,\n",
    "        outcome_measure_denom_counts,\n",
    "        outcome_measure_groups_result,\n",
    "        outcome_measure_analyses,\n",
    "        outcome_measure_comparison_groups,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c1c1524-e6c9-4754-a0db-19500bf0ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def transform_participant_flow_module(study_key: str, study_data: pd.Series) -> Tuple:\n",
    " \n",
    "    flow_groups = []\n",
    "    flow_periods = []\n",
    "    flow_period_milestones = []\n",
    "    flow_period_milestone_achievements = []\n",
    "    flow_period_withdrawals = []\n",
    "    flow_period_withdrawal_reasons = []\n",
    "\n",
    "    flow_module_index = NON_SCALAR_FIELDS[\"participant_flow\"][\"index_field\"]\n",
    "\n",
    "    # flow groups\n",
    "    flow_group_list = study_data.get(f\"{flow_module_index}.groups\")\n",
    "    if isinstance(flow_group_list, (list, np.ndarray)) and len(flow_group_list) > 0:\n",
    "        for flow in flow_group_list:\n",
    "            group_id = flow.get(\"id\")\n",
    "            group_key = generate_key(study_key, group_id)\n",
    "\n",
    "            flow_groups.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"group_key\": group_key,\n",
    "                    \"id\": group_id,\n",
    "                    \"title\": flow.get(\"title\"),\n",
    "                    \"description\": flow.get(\"description\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # flow periods\n",
    "\n",
    "    flow_period_list = study_data.get(f\"{flow_module_index}.periods\")\n",
    "    if isinstance(flow_period_list, (list, np.ndarray)) and len(flow_period_list) > 0:\n",
    "        for period in flow_period_list:\n",
    "            period_title = period.get(\"title\")\n",
    "            period_key = generate_key(study_key, period_title)\n",
    "\n",
    "            # flow periods\n",
    "            flow_periods.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"period_key\": period_key,\n",
    "                    \"title\": period.get(\"title\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # flow milestones\n",
    "            period_milestones = period.get(\"milestones\")\n",
    "            if (\n",
    "                isinstance(period_milestones, (list, np.ndarray))\n",
    "                and len(period_milestones) > 0\n",
    "            ):\n",
    "                for period_milestone in period_milestones:\n",
    "                    milestone_type = period_milestone.get(\"type\")\n",
    "                    milestone_comment = period_milestone.get(\"comment\")\n",
    "                    milestone_key = generate_key(\n",
    "                        study_key, period_key, milestone_type, milestone_comment\n",
    "                    )\n",
    "\n",
    "                    flow_period_milestones.append(\n",
    "                        {\n",
    "                            \"study_key\": study_key,\n",
    "                            \"period_key\": period_key,\n",
    "                            \"milestone_key\": milestone_key,\n",
    "                            \"type\": milestone_type,\n",
    "                            \"comment\": milestone_comment,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    # milestone achievements\n",
    "                    milestone_achievements = period_milestone.get(\"achievements\")\n",
    "                    if (\n",
    "                        isinstance(milestone_achievements, (list, np.ndarray))\n",
    "                        and len(milestone_achievements) > 0\n",
    "                    ):\n",
    "                        for achievement in milestone_achievements:\n",
    "                            group_id = achievement.get(\"groupId\")\n",
    "                            group_key = generate_key(study_key, group_id)\n",
    "                            flow_period_milestone_achievements.append(\n",
    "                                {\n",
    "                                    \"study_key\": study_key,\n",
    "                                    \"period_key\": period_key,\n",
    "                                    \"milestone_key\": milestone_key,\n",
    "                                    \"group_key\": group_key,\n",
    "                                    \"group_id\": group_id,\n",
    "                                    \"comment\": achievement.get(\"comment\"),\n",
    "                                    \"num_subjects\": achievement.get(\"numSubjects\"),\n",
    "                                    \"num_units\": achievement.get(\"numUnits\"),\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "            period_withdrawals = period.get(\"dropWithdraws\")\n",
    "            if (\n",
    "                isinstance(period_withdrawals, (list, np.ndarray))\n",
    "                and len(period_withdrawals) > 0\n",
    "            ):\n",
    "                for withdrawal in period_withdrawals:\n",
    "                    withdrawal_type = withdrawal.get(\"type\")\n",
    "                    withdrawal_comment = withdrawal.get(\"comment\")\n",
    "                    withdrawal_key = generate_key(\n",
    "                        study_key, period_key, withdrawal_type, withdrawal_comment\n",
    "                    )\n",
    "\n",
    "                    flow_period_withdrawals.append(\n",
    "                        {\n",
    "                            \"study_key\": study_key,\n",
    "                            \"period_key\": period_key,\n",
    "                            \"withdrawal_key\": withdrawal_key,\n",
    "                            \"type\": withdrawal_type,\n",
    "                            \"comment\": withdrawal_comment,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    # withdrawal reasons\n",
    "                    period_withdrawal_reasons = withdrawal.get(\"reasons\")\n",
    "\n",
    "                    if (\n",
    "                        isinstance(period_withdrawal_reasons, (list, np.ndarray))\n",
    "                        and len(period_withdrawal_reasons) > 0\n",
    "                    ):\n",
    "                        for reason in period_withdrawal_reasons:\n",
    "\n",
    "                            reason_group_id = reason.get(\"groupId\")\n",
    "                            reason_comment = reason.get(\"comment\")\n",
    "\n",
    "                            reason_key = generate_key(\n",
    "                                study_key,\n",
    "                                period_key,\n",
    "                                withdrawal_key,\n",
    "                                reason_group_id,\n",
    "                                reason_comment,\n",
    "                            )\n",
    "\n",
    "                            group_key = generate_key(study_key, reason_group_id)\n",
    "\n",
    "                            flow_period_withdrawal_reasons.append(\n",
    "                                {\n",
    "                                    \"study_key\": study_key,\n",
    "                                    \"period_key\": period_key,\n",
    "                                    \"withdrawal_key\": withdrawal_key,\n",
    "                                    \"reason_key\": reason_key,\n",
    "                                    \"group_id\": reason_group_id,\n",
    "                                    \"group_key\": group_key,\n",
    "                                    \"reason\": reason_comment,\n",
    "                                    \"num_subjects\": reason.get(\"numSubjects\"),\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "    return (\n",
    "        flow_groups,\n",
    "        flow_periods,\n",
    "        flow_period_milestones,\n",
    "        flow_period_milestone_achievements,\n",
    "        flow_period_withdrawals,\n",
    "        flow_period_withdrawal_reasons,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef7ece32-688d-48c2-ae4a-99baf09bc394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def transform_adverse_events_module(study_key: str, study_data: pd.Series) -> Tuple:\n",
    "   \n",
    "    adverse_events = []\n",
    "    event_groups = []\n",
    "    serious_events = []\n",
    "    serious_event_stats = []\n",
    "    other_events = []\n",
    "    other_event_stats = []\n",
    "\n",
    "    events_index = NON_SCALAR_FIELDS[\"adverse_events\"][\"index_field\"]\n",
    "\n",
    "    description = study_data.get(f\"{events_index}.description\")\n",
    "    adverse_event_key = generate_key(study_key, description)\n",
    "\n",
    "    # AE fields are scalar\n",
    "    adverse_events.append(\n",
    "        {\n",
    "            \"adverse_event_key\": adverse_event_key,\n",
    "            \"study_key\": study_key,\n",
    "            \"description\": description,\n",
    "            \"frequency_threshold\": study_data.get(f\"{events_index}.frequencyThreshold\"),\n",
    "            \"time_frame\": study_data.get(f\"{events_index}.timeFrame\"),\n",
    "            \"mortality_cmt\": study_data.get(f\"{events_index}.allCauseMortalityComment\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    event_group_list = study_data.get(f\"{events_index}.eventGroups\")\n",
    "\n",
    "    if isinstance(event_group_list, (list, np.ndarray)) and len(event_group_list) > 0:\n",
    "        for event_group in event_group_list:\n",
    "            group_id = event_group.get(\"id\")\n",
    "            event_group_key = generate_key(study_key, adverse_event_key, group_id)\n",
    "\n",
    "            event_groups.append(\n",
    "                {\n",
    "                    \"event_group_key\": event_group_key,\n",
    "                    \"study_key\": study_key,\n",
    "                    \"adverse_event_key\": adverse_event_key,\n",
    "                    \"group_id\": group_id,\n",
    "                    \"title\": event_group.get(\"title\"),\n",
    "                    \"description\": event_group.get(\"description\"),\n",
    "                    \"num_deaths\": event_group.get(\"deathsNumAffected\"),\n",
    "                    \"num_deaths_at_risk\": event_group.get(\"deathsNumAtRisk\"),\n",
    "                    \"num_serious\": event_group.get(\"seriousNumAffected\"),\n",
    "                    \"num_serious_at_risk\": event_group.get(\"seriousNumAtRisk\"),\n",
    "                    \"num_other\": event_group.get(\"otherNumAffected\"),\n",
    "                    \"num_other_at_risk\": event_group.get(\"otherNumAtRisk\"),\n",
    "                }\n",
    "            )\n",
    "    # serious AEs\n",
    "    serious_events_list = study_data.get(f\"{events_index}.seriousEvents\")\n",
    "\n",
    "    if isinstance(serious_events_list, (list, np.ndarray)) and len(serious_events_list) > 0:\n",
    "        for serious_event in serious_events_list:\n",
    "            term = serious_event.get(\"term\")\n",
    "            serious_event_key = generate_key(study_key, adverse_event_key, term)\n",
    "\n",
    "            serious_events.append(\n",
    "                {\n",
    "                    \"serious_event_key\": serious_event_key,\n",
    "                    \"adverse_event_key\": adverse_event_key,\n",
    "                    \"study_key\": study_key,\n",
    "                    \"term\": term,\n",
    "                    \"organ_system\": serious_event.get(\"organSystem\"),\n",
    "                    \"source_vocab\": serious_event.get(\"sourceVocabulary\"),\n",
    "                    \"assessment_type\": serious_event.get(\"assessmentType\"),\n",
    "                    \"notes\": serious_event.get(\"notes\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            serious_event_stats_list = serious_event.get(\"stats\")\n",
    "            if (\n",
    "                isinstance(serious_event_stats_list, (list, np.ndarray))\n",
    "                and len(serious_event_stats_list) > 0\n",
    "            ):\n",
    "                for serious_event_stat in serious_event_stats_list:\n",
    "                    group_id = serious_event_stat.get(\"groupId\")\n",
    "\n",
    "                    group_key = generate_key(study_key, adverse_event_key, group_id)\n",
    "                    event_stat_key = generate_key(\n",
    "                        study_key, adverse_event_key, serious_event_key, group_id\n",
    "                    )\n",
    "\n",
    "                    serious_event_stats.append(\n",
    "                        {\n",
    "                            \"event_stat_key\": event_stat_key,\n",
    "                            \"adverse_event_key\": adverse_event_key,\n",
    "                            \"serious_event_key\": serious_event_key,\n",
    "                            \"study_key\": study_key,\n",
    "                            \"group_key\": group_key,\n",
    "                            \"group_id\": group_id,\n",
    "                            \"num_events\": serious_event_stat.get(\"numEvents\"),\n",
    "                            \"num_affected\": serious_event_stat.get(\"numAffected\"),\n",
    "                            \"num_at_risk\": serious_event_stat.get(\"numAtRisk\"),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    # other AEs\n",
    "    other_events_list = study_data.get(f\"{events_index}.otherEvents\")\n",
    "    if isinstance(other_events_list, (list, np.ndarray)) and len(other_events_list) > 0:\n",
    "        for other_event in other_events_list:\n",
    "            term = other_event.get(\"term\")\n",
    "            other_event_key = generate_key(study_key, adverse_event_key, term)\n",
    "\n",
    "            other_events.append(\n",
    "                {\n",
    "                    \"other_event_key\": other_event_key,\n",
    "                    \"adverse_event_key\": adverse_event_key,\n",
    "                    \"study_key\": study_key,\n",
    "                    \"term\": term,\n",
    "                    \"organ_system\": other_event.get(\"organSystem\"),\n",
    "                    \"source_vocab\": other_event.get(\"sourceVocabulary\"),\n",
    "                    \"assessment_type\": other_event.get(\"assessmentType\"),\n",
    "                    \"notes\": other_event.get(\"notes\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            other_event_stats_list = other_event.get(\"stats\")\n",
    "            if (\n",
    "                isinstance(other_event_stats_list, (list, np.ndarray))\n",
    "                and len(other_event_stats_list) > 0\n",
    "            ):\n",
    "                for other_event_stat in other_event_stats_list:\n",
    "                    group_id = other_event_stat.get(\"groupId\")\n",
    "\n",
    "                    group_key = generate_key(study_key, adverse_event_key, group_id)\n",
    "                    event_stat_key = generate_key(\n",
    "                        study_key, adverse_event_key, other_event_key, group_id\n",
    "                    )\n",
    "\n",
    "                    other_event_stats.append(\n",
    "                        {\n",
    "                            \"event_stat_key\": event_stat_key,\n",
    "                            \"other_event_key\": other_event_key,\n",
    "                            \"adverse_event_key\": adverse_event_key,\n",
    "                            \"study_key\": study_key,\n",
    "                            \"group_key\": group_key,\n",
    "                            \"group_id\": group_id,\n",
    "                            \"num_events\": other_event_stat.get(\"numEvents\"),\n",
    "                            \"num_affected\": other_event_stat.get(\"numAffected\"),\n",
    "                            \"num_at_risk\": other_event_stat.get(\"numAtRisk\"),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    return (\n",
    "        adverse_events,\n",
    "        event_groups,\n",
    "        serious_events,\n",
    "        serious_event_stats,\n",
    "        other_events,\n",
    "        other_event_stats,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b373cec-47e0-454c-a4c8-438afa3b4307",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_annotations_module(study_key: str, study_data: pd.Series) -> List:\n",
    "    \"\"\"\n",
    "    Extract FDAAA 801 regulatory violations.\n",
    "    These indicate FDA compliance issues (non-submission, false information, penalties).\n",
    "    \"\"\"\n",
    "    violations = []\n",
    "\n",
    "    annotations_index = NON_SCALAR_FIELDS[\"annotations\"][\"index_field\"]\n",
    "    violations_list  = study_data.get(annotations_index)\n",
    "\n",
    "    if isinstance(violations_list, (list, np.ndarray)) and len(violations_list) > 0:\n",
    "\n",
    "        for violation in violations_list:\n",
    "            issued_date = violation.get(\"issuedDate\")\n",
    "            event_type = violation.get(\"type\")\n",
    "            violation_key = generate_key(study_key, issued_date, event_type)\n",
    "\n",
    "            violations.append(\n",
    "                {\n",
    "                    \"violation_key\": violation_key,\n",
    "                    \"study_key\": study_key,\n",
    "                    \"violation_type\": event_type,\n",
    "                    \"issued_date\": issued_date,\n",
    "                    \"description\": violation.get(\"description\"),\n",
    "                    \"creation_date\": violation.get(\"creationDate\"),\n",
    "                    \"release_date\": violation.get(\"releaseDate\"),\n",
    "                    \"posted_date\": violation.get(\"postedDate\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return violations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8904e83a-e5a2-46d1-8720-f9c773a98b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_conditions_browse_module(study_key: str, study_data: pd.Series) -> Tuple:\n",
    "   \n",
    "    conditions_mesh = []\n",
    "    study_conditions_mesh = []\n",
    "\n",
    "    conditions_mesh_ancestors = []\n",
    "    study_conditions_mesh_ancestors = []\n",
    "\n",
    "    conditions_browse_leaves = []\n",
    "    study_conditions_browse_leaves = []\n",
    "\n",
    "    conditions_browse_branches = []\n",
    "    study_conditions_browse_branches = []\n",
    "\n",
    "    conditions_browse_index = NON_SCALAR_FIELDS[\"conditions_browse\"][\"index_field\"]\n",
    "\n",
    "    meshes = study_data.get(f\"{conditions_browse_index}.meshes\")\n",
    "    if isinstance(meshes, (list, np.ndarray)) and len(meshes) > 0:\n",
    "        for mesh in meshes:\n",
    "            mesh_terms = mesh.get(\"term\")\n",
    "\n",
    "            if isinstance(mesh_terms, str) and mesh_terms:\n",
    "                terms = mesh_terms.split(\",\")\n",
    "                for term in terms:\n",
    "                    term = term.strip()\n",
    "                    mesh_key = generate_key(term)\n",
    "                    conditions_mesh.append(\n",
    "                        {\n",
    "                            \"mesh_key\": mesh_key,\n",
    "                            \"mesh_id\": mesh.get(\"id\"),\n",
    "                            \"mesh_term\": term.lower(),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    study_conditions_mesh.append(\n",
    "                        {\"mesh_key\": mesh_key, \"study_key\": study_key}\n",
    "                    )\n",
    "\n",
    "    ancestors_list = study_data.get(f\"{conditions_browse_index}.ancestors\")\n",
    "    if (\n",
    "        isinstance(ancestors_list, (list, np.ndarray))\n",
    "        and len(ancestors_list) > 0\n",
    "    ):\n",
    "        for ancestor in ancestors_list:\n",
    "            ancestor_terms = ancestor.get(\"term\")\n",
    "\n",
    "            if isinstance(ancestor_terms, str) and ancestor_terms:\n",
    "                terms = ancestor_terms.split(\",\") #sometimes MeSH terms are comma separated keywords\n",
    "                for term in terms:\n",
    "                    term = term.strip()\n",
    "                    ancestor_key = generate_key(term)\n",
    "                    conditions_mesh_ancestors.append(\n",
    "                        {\n",
    "                            \"ancestor_key\": ancestor_key,\n",
    "                            \"ancestor_id\": ancestor.get(\"id\"),\n",
    "                            \"term\": term.lower(),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    study_conditions_mesh_ancestors.append(\n",
    "                        {\"ancestor_key\": ancestor_key, \"study_key\": study_key}\n",
    "                    )\n",
    "\n",
    "    mesh_browse_leaves = study_data.get(f\"{conditions_browse_index}.browseLeaves\")\n",
    "    if (\n",
    "        isinstance(mesh_browse_leaves, (list, np.ndarray))\n",
    "        and len(mesh_browse_leaves) > 0\n",
    "    ):\n",
    "        for browse_leaf in mesh_browse_leaves:\n",
    "            leaf_id = browse_leaf.get(\"id\")\n",
    "            leaf_key = generate_key(leaf_id)\n",
    "\n",
    "            conditions_browse_leaves.append(\n",
    "                {\n",
    "                    \"leaf_key\": leaf_key,\n",
    "                    \"leaf_id\": leaf_id,\n",
    "                    \"name\": browse_leaf.get(\"name\").lower(),\n",
    "                    \"as_found\": browse_leaf.get(\"asFound\"),\n",
    "                    \"relevance\": browse_leaf.get(\"relevance\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            study_conditions_browse_leaves.append(\n",
    "                {\"leaf_key\": leaf_key, \"study_key\": study_key}\n",
    "            )\n",
    "\n",
    "    mesh_browse_branches = study_data.get(f\"{conditions_browse_index}.browseBranches\")\n",
    "\n",
    "    if (\n",
    "        isinstance(mesh_browse_branches, (list, np.ndarray))\n",
    "        and len(mesh_browse_branches) > 0\n",
    "    ):\n",
    "        for browse_branch in mesh_browse_branches:\n",
    "            branch_id = browse_branch.get(\"id\")\n",
    "            branch_key = generate_key(branch_id)\n",
    "\n",
    "            conditions_browse_branches.append(\n",
    "                {\n",
    "                    \"branch_key\": branch_key,\n",
    "                    \"branch_id\": branch_id,\n",
    "                    \"name\": browse_branch.get(\"name\").lower(),\n",
    "                    \"as_found\": browse_branch.get(\"asFound\"),\n",
    "                    \"relevance\": browse_branch.get(\"relevance\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            study_conditions_browse_branches.append(\n",
    "                {\"branch_key\": branch_key, \"study_key\": study_key}\n",
    "            )\n",
    "\n",
    "    return (\n",
    "        conditions_mesh,\n",
    "        study_conditions_mesh,\n",
    "        conditions_mesh_ancestors,\n",
    "        study_conditions_mesh_ancestors,\n",
    "        conditions_browse_leaves,\n",
    "        study_conditions_browse_leaves,\n",
    "        conditions_browse_branches,\n",
    "        study_conditions_browse_branches,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21046d43-daa2-4f45-bec5-190fabaf68cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_interventions_browse_module(\n",
    "    study_key: str, study_data: pd.Series\n",
    ") -> Tuple:\n",
    "\n",
    "    interventions_mesh = []\n",
    "    study_interventions_mesh = []\n",
    "\n",
    "    interventions_mesh_ancestors = []\n",
    "    study_interventions_mesh_ancestors = []\n",
    "\n",
    "    interventions_browse_leaves = []\n",
    "    study_interventions_browse_leaves = []\n",
    "\n",
    "    interventions_browse_branches = []\n",
    "    study_interventions_browse_branches = []\n",
    "\n",
    "    interventions_browse_index = NON_SCALAR_FIELDS[\"interventions_browse\"][\n",
    "        \"index_field\"\n",
    "    ]\n",
    "\n",
    "    meshes = study_data.get(f\"{interventions_browse_index}.meshes\")\n",
    "    if isinstance(meshes, (list, np.ndarray)) and len(meshes) > 0:\n",
    "        for mesh in meshes:\n",
    "            mesh_terms = mesh.get(\"term\")\n",
    "\n",
    "            if isinstance(mesh_terms, str) and mesh_terms:\n",
    "                terms = mesh_terms.split(\",\")\n",
    "                for term in terms:\n",
    "                    term = term.strip()\n",
    "                    mesh_key = generate_key(term)\n",
    "                    interventions_mesh.append(\n",
    "                        {\n",
    "                            \"mesh_key\": mesh_key,\n",
    "                            \"mesh_id\": mesh.get(\"id\"),\n",
    "                            \"mesh_term\": term.lower(),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    study_interventions_mesh.append(\n",
    "                        {\"mesh_key\": mesh_key, \"study_key\": study_key}\n",
    "                    )\n",
    "\n",
    "    ancestors_list = study_data.get(f\"{interventions_browse_index}.ancestors\")\n",
    "    if (\n",
    "        isinstance(ancestors_list, (list, np.ndarray))\n",
    "        and len(ancestors_list) > 0\n",
    "    ):\n",
    "\n",
    "        for ancestor in ancestors_list:\n",
    "            ancestor_terms = ancestor.get(\"term\")\n",
    "\n",
    "            if isinstance(ancestor_terms, str) and ancestor_terms:\n",
    "                terms = ancestor_terms.split(\",\")\n",
    "                for term in terms:\n",
    "                    term = term.strip()\n",
    "                    ancestor_key = generate_key(term)\n",
    "                    interventions_mesh_ancestors.append(\n",
    "                        {\n",
    "                            \"ancestor_key\": ancestor_key,\n",
    "                            \"study_key\": study_key,\n",
    "                            \"ancestor_id\": ancestor.get(\"id\"),\n",
    "                            \"ancestor_term\": term.lower(),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    study_interventions_mesh_ancestors.append(\n",
    "                        {\"ancestor_key\": ancestor_key, \"study_key\": study_key}\n",
    "                    )\n",
    "\n",
    "    mesh_browse_leaves = study_data.get(f\"{interventions_browse_index}.browseLeaves\")\n",
    "    if (\n",
    "        isinstance(mesh_browse_leaves, (list, np.ndarray))\n",
    "        and len(mesh_browse_leaves) > 0\n",
    "    ):\n",
    "        for browse_leaf in mesh_browse_leaves:\n",
    "            leaf_id = browse_leaf.get(\"id\")\n",
    "            leaf_key = generate_key(leaf_id)\n",
    "\n",
    "            interventions_browse_leaves.append(\n",
    "                {\n",
    "                    \"leaf_key\": leaf_key,\n",
    "                    \"name\": browse_leaf.get(\"name\").lower(),\n",
    "                    \"as_found\": browse_leaf.get(\"asFound\"),\n",
    "                    \"relevance\": browse_leaf.get(\"relevance\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            study_interventions_browse_leaves.append(\n",
    "                {\"leaf_key\": leaf_key, \"study_key\": study_key}\n",
    "            )\n",
    "\n",
    "    mesh_browse_branches = study_data.get(\n",
    "        f\"{interventions_browse_index}.browseBranches\"\n",
    "    )\n",
    "    if (\n",
    "        isinstance(mesh_browse_branches, (list, np.ndarray))\n",
    "        and len(mesh_browse_branches) > 0\n",
    "    ):\n",
    "        for browse_branch in mesh_browse_branches:\n",
    "            branch_id = browse_branch.get(\"id\")\n",
    "            branch_key = generate_key(branch_id)\n",
    "\n",
    "            interventions_browse_branches.append(\n",
    "                {\n",
    "                    \"branch_key\": branch_key,\n",
    "                    \"name\": browse_branch.get(\"name\").lower(),\n",
    "                    \"as_found\": browse_branch.get(\"asFound\"),\n",
    "                    \"relevance\": browse_branch.get(\"relevance\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            study_interventions_browse_branches.append(\n",
    "                {\"branch_key\": branch_key, \"study_key\": study_key}\n",
    "            )\n",
    "\n",
    "    return (\n",
    "        interventions_mesh,\n",
    "        study_interventions_mesh,\n",
    "        interventions_mesh_ancestors,\n",
    "        study_interventions_mesh_ancestors,\n",
    "        interventions_browse_leaves,\n",
    "        study_interventions_browse_leaves,\n",
    "        interventions_browse_branches,\n",
    "        study_interventions_browse_branches,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e9ce018-a69b-474f-b494-7f5df18ad9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def post_process_tables(results: Dict[str, List[Dict]]) -> List[pd.DataFrame]:\n",
    " \n",
    "    df_studies = pd.DataFrame(results[\"studies\"])\n",
    "\n",
    "    # identificationModule\n",
    "    df_secondary_ids = pd.DataFrame(results[\"secondary_ids\"])\n",
    "    df_nct_aliases = pd.DataFrame(results[\"nct_aliases\"])\n",
    "\n",
    "    # sponsorCollaboratorsModule\n",
    "    df_sponsors = pd.DataFrame(results[\"sponsors\"])\n",
    "    df_study_sponsors = pd.DataFrame(results[\"study_sponsors\"])\n",
    "    df_collaborators = pd.DataFrame(results[\"collaborators\"])\n",
    "    df_study_collaborators = pd.DataFrame(results[\"study_collaborators\"])\n",
    "\n",
    "    # conditionsModule\n",
    "    df_conditions = pd.DataFrame(results[\"conditions\"])\n",
    "    df_study_conditions = pd.DataFrame(results[\"study_conditions\"])\n",
    "    df_keywords = pd.DataFrame(results[\"keywords\"])\n",
    "    df_study_keywords = pd.DataFrame(results[\"study_keywords\"])\n",
    "\n",
    "    # armsInterventionsModule\n",
    "    df_arm_groups = pd.DataFrame(results[\"arm_groups\"])\n",
    "    df_arm_interventions = pd.DataFrame(results[\"arm_interventions\"])\n",
    "    df_interventions = pd.DataFrame(results[\"interventions\"])\n",
    "    df_study_interventions = pd.DataFrame(results[\"study_interventions\"])\n",
    "    df_other_intervention_names = pd.DataFrame(results[\"other_intervention_names\"])\n",
    "    df_study_intervention_aliases = pd.DataFrame(results[\"study_intervention_aliases\"])\n",
    "\n",
    "    # outcomesModule\n",
    "    df_primary_outcomes = pd.DataFrame(results[\"primary_outcomes\"])\n",
    "    df_secondary_outcomes = pd.DataFrame(results[\"secondary_outcomes\"])\n",
    "    df_other_outcomes = pd.DataFrame(results[\"other_outcomes\"])\n",
    "\n",
    "    # contactsLocationsModule\n",
    "    df_central_contacts = pd.DataFrame(results[\"central_contacts\"])\n",
    "    df_study_central_contacts = pd.DataFrame(results[\"study_central_contacts\"])\n",
    "    df_locations = pd.DataFrame(results[\"locations\"])\n",
    "    df_study_locations = pd.DataFrame(results[\"study_locations\"])\n",
    "\n",
    "    # referencesModule\n",
    "    df_references = pd.DataFrame(results[\"references\"])\n",
    "    df_link_references = pd.DataFrame(results[\"link_references\"])\n",
    "    df_ipd_references = pd.DataFrame(results[\"ipd_references\"])\n",
    "\n",
    "    # outcomeMeasuresModule\n",
    "    df_outcome_measures = pd.DataFrame(results[\"outcome_measures\"])\n",
    "    df_outcome_measure_groups = pd.DataFrame(results[\"outcome_measure_groups\"])\n",
    "    df_outcome_measure_denom_units = pd.DataFrame(\n",
    "        results[\"outcome_measure_denom_units\"]\n",
    "    )\n",
    "    df_outcome_measure_denom_counts = pd.DataFrame(\n",
    "        results[\"outcome_measure_denom_counts\"]\n",
    "    )\n",
    "    df_outcome_measure_groups_result = pd.DataFrame(\n",
    "        results[\"outcome_measure_groups_result\"]\n",
    "    )\n",
    "    df_outcome_measure_analyses = pd.DataFrame(results[\"outcome_measure_analyses\"])\n",
    "    df_outcome_measure_comparison_groups = pd.DataFrame(\n",
    "        results[\"outcome_measure_comparison_groups\"]\n",
    "    )\n",
    "\n",
    "    # participantFlowModule\n",
    "    df_flow_groups = pd.DataFrame(results[\"flow_groups\"])\n",
    "    df_flow_periods = pd.DataFrame(results[\"flow_periods\"])\n",
    "    df_flow_period_milestones = pd.DataFrame(results[\"flow_period_milestones\"])\n",
    "    df_flow_period_milestone_achievements = pd.DataFrame(\n",
    "        results[\"flow_period_milestone_achievements\"]\n",
    "    )\n",
    "    df_flow_period_withdrawals = pd.DataFrame(results[\"df_flow_period_withdrawals\"])\n",
    "    df_flow_period_withdrawal_reasons = pd.DataFrame(\n",
    "        results[\"flow_period_withdrawal_reasons\"]\n",
    "    )\n",
    "\n",
    "    # adverseEventsModule\n",
    "    df_adverse_events = pd.DataFrame(results[\"adverse_events\"])\n",
    "    df_event_groups = pd.DataFrame(results[\"event_groups\"])\n",
    "    df_serious_events = pd.DataFrame(results[\"serious_events\"])\n",
    "    df_serious_event_stats = pd.DataFrame(results[\"serious_event_stats\"])\n",
    "    df_other_events = pd.DataFrame(results[\"other_events\"])\n",
    "    df_other_event_stats = pd.DataFrame(results[\"other_event_stats\"])\n",
    "\n",
    "    # annotationModule\n",
    "    df_violations = pd.DataFrame(results[\"violations\"])\n",
    "\n",
    "    # conditionBrowseModule\n",
    "    df_conditions_mesh = pd.DataFrame(results[\"conditions_mesh\"])\n",
    "    df_study_conditions_mesh = pd.DataFrame(results[\"study_conditions_mesh\"])\n",
    "    df_conditions_mesh_ancestors = pd.DataFrame(results[\"conditions_mesh_ancestors\"])\n",
    "    df_study_conditions_mesh_ancestors = pd.DataFrame(\n",
    "        results[\"study_conditions_mesh_ancestors\"]\n",
    "    )\n",
    "    df_conditions_browse_leaves = pd.DataFrame(results[\"conditions_browse_leaves\"])\n",
    "    df_study_conditions_browse_leaves = pd.DataFrame(\n",
    "        results[\"study_conditions_browse_leaves\"]\n",
    "    )\n",
    "    df_conditions_browse_branches = pd.DataFrame(results[\"conditions_browse_branches\"])\n",
    "    df_study_conditions_browse_branches = pd.DataFrame(\n",
    "        results[\"study_conditions_browse_branches\"]\n",
    "    )\n",
    "\n",
    "    # interventionBrowseModule\n",
    "    df_interventions_mesh = pd.DataFrame(results[\"interventions_mesh\"])\n",
    "    df_study_interventions_mesh = pd.DataFrame(results[\"study_interventions_mesh\"])\n",
    "    df_interventions_mesh_ancestors = pd.DataFrame(\n",
    "        results[\"interventions_mesh_ancestors\"]\n",
    "    )\n",
    "    df_study_interventions_mesh_ancestors = pd.DataFrame(\n",
    "        results[\"study_interventions_mesh_ancestors\"]\n",
    "    )\n",
    "    df_interventions_browse_leaves = pd.DataFrame(\n",
    "        results[\"interventions_browse_leaves\"]\n",
    "    )\n",
    "    df_study_interventions_browse_leaves = pd.DataFrame(\n",
    "        results[\"study_interventions_browse_leaves\"]\n",
    "    )\n",
    "    df_interventions_browse_branches = pd.DataFrame(\n",
    "        results[\"interventions_browse_branches\"]\n",
    "    )\n",
    "    df_study_interventions_browse_branches = pd.DataFrame(\n",
    "        results[\"study_interventions_browse_branches\"]\n",
    "    )\n",
    "\n",
    "    # dedupe\n",
    "\n",
    "    return [\n",
    "        df_studies,\n",
    "        df_secondary_ids,\n",
    "        df_nct_aliases,\n",
    "        df_sponsors,\n",
    "        df_study_sponsors,\n",
    "        df_collaborators,\n",
    "        df_study_collaborators,\n",
    "        df_conditions,\n",
    "        df_study_conditions,\n",
    "        df_keywords,\n",
    "        df_study_keywords,\n",
    "        df_arm_groups,\n",
    "        df_arm_interventions,\n",
    "        df_interventions,\n",
    "        df_study_interventions,\n",
    "        df_other_intervention_names,\n",
    "        df_study_intervention_aliases,\n",
    "        df_primary_outcomes,\n",
    "        df_secondary_outcomes,\n",
    "        df_other_outcomes,\n",
    "        df_central_contacts,\n",
    "        df_study_central_contacts,\n",
    "        df_locations,\n",
    "        df_study_locations,\n",
    "        df_references,\n",
    "        df_link_references,\n",
    "        df_ipd_references,\n",
    "        df_outcome_measures,\n",
    "        df_outcome_measure_groups,\n",
    "        df_outcome_measure_denom_units,\n",
    "        df_outcome_measure_denom_counts,\n",
    "        df_outcome_measure_groups_result,\n",
    "        df_outcome_measure_analyses,\n",
    "        df_outcome_measure_comparison_groups,\n",
    "        df_flow_groups,\n",
    "        df_flow_periods,\n",
    "        df_flow_period_milestones,\n",
    "        df_flow_period_milestone_achievements,\n",
    "        df_flow_period_withdrawals,\n",
    "        df_flow_period_withdrawal_reasons,\n",
    "        df_adverse_events,\n",
    "        df_event_groups,\n",
    "        df_serious_events,\n",
    "        df_serious_event_stats,\n",
    "        df_other_events,\n",
    "        df_other_event_stats,\n",
    "        df_violations,\n",
    "        df_conditions_mesh,\n",
    "        df_study_conditions_mesh,\n",
    "        df_conditions_mesh_ancestors,\n",
    "        df_study_conditions_mesh_ancestors,\n",
    "        df_conditions_browse_leaves,\n",
    "        df_study_conditions_browse_leaves,\n",
    "        df_conditions_browse_branches,\n",
    "        df_study_conditions_browse_branches,\n",
    "        df_interventions_mesh,\n",
    "        df_study_interventions_mesh,\n",
    "        df_interventions_mesh_ancestors,\n",
    "        df_study_interventions_mesh_ancestors,\n",
    "        df_interventions_browse_leaves,\n",
    "        df_study_interventions_browse_leaves,\n",
    "        df_interventions_browse_branches,\n",
    "        df_study_interventions_browse_branches,\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77c9384e-52e5-4cee-a220-460ad7ba6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_studies_batch():\n",
    "    try:\n",
    "        batch_result = process_study_file(\"1.parquet\")\n",
    "        merged_batch_results = merge_batch_results(batch_result)\n",
    "        dfs = post_process_tables(merged_batch_results)\n",
    "\n",
    "        return dfs\n",
    "\n",
    "    except Exception as e:\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e732542e-3452-490a-af84-fbe3f22716a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df_studies,\n",
    "    df_secondary_ids,\n",
    "    df_nct_aliases,\n",
    "    df_sponsors,\n",
    "    df_study_sponsors,\n",
    "    df_collaborators,\n",
    "    df_study_collaborators,\n",
    "    df_conditions,\n",
    "    df_study_conditions,\n",
    "    df_keywords,\n",
    "    df_study_keywords,\n",
    "    df_arm_groups,\n",
    "    df_arm_interventions,\n",
    "    df_interventions,\n",
    "    df_study_interventions,\n",
    "    df_other_intervention_names,\n",
    "    df_study_intervention_aliases,\n",
    "    df_primary_outcomes,\n",
    "    df_secondary_outcomes,\n",
    "    df_other_outcomes,\n",
    "    df_central_contacts,\n",
    "    df_study_central_contacts,\n",
    "    df_locations,\n",
    "    df_study_locations,\n",
    "    df_references,\n",
    "    df_link_references,\n",
    "    df_ipd_references,\n",
    "    df_outcome_measures,\n",
    "    df_outcome_measure_groups,\n",
    "    df_outcome_measure_denom_units,\n",
    "    df_outcome_measure_denom_counts,\n",
    "    df_outcome_measure_groups_result,\n",
    "    df_outcome_measure_analyses,\n",
    "    df_outcome_measure_comparison_groups,\n",
    "    df_flow_groups,\n",
    "    df_flow_periods,\n",
    "    df_flow_period_milestones,\n",
    "    df_flow_period_milestone_achievements,\n",
    "    df_flow_period_withdrawals,\n",
    "    df_flow_period_withdrawal_reasons,\n",
    "    df_adverse_events,\n",
    "    df_event_groups,\n",
    "    df_serious_events,\n",
    "    df_serious_event_stats,\n",
    "    df_other_events,\n",
    "    df_other_event_stats,\n",
    "    df_violations,\n",
    "    df_conditions_mesh,\n",
    "    df_study_conditions_mesh,\n",
    "    df_conditions_mesh_ancestors,\n",
    "    df_study_conditions_mesh_ancestors,\n",
    "    df_conditions_browse_leaves,\n",
    "    df_study_conditions_browse_leaves,\n",
    "    df_conditions_browse_branches,\n",
    "    df_study_conditions_browse_branches,\n",
    "    df_interventions_mesh,\n",
    "    df_study_interventions_mesh,\n",
    "    df_interventions_mesh_ancestors,\n",
    "    df_study_interventions_mesh_ancestors,\n",
    "    df_interventions_browse_leaves,\n",
    "    df_study_interventions_browse_leaves,\n",
    "    df_interventions_browse_branches,\n",
    "    df_study_interventions_browse_branches,\n",
    "    \n",
    ") = transform_studies_batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "857f4ecf-c2e9-4131-a33d-f7b94e1e0588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"SPONSORS {len(df_sponsors)}\")\n",
    "# df_sponsors = df_sponsors.drop_duplicates(subset=[\"sponsor_key\"])\n",
    "# print(f\"DEDUPED SPONSORS {len(df_sponsors)}\")\n",
    "\n",
    "# print(f\"STUDY SPONSORS {len(df_study_sponsors)}\")\n",
    "# df_study_sponsors = df_study_sponsors.drop_duplicates(subset=[\"sponsor_key\", \"study_key\"])\n",
    "# print(f\"DEDUPED STUDY SPONSORS {len(df_study_sponsors)}\")\n",
    "# print(\"----------------\")\n",
    "\n",
    "# print(f\"CONDITIONS {len(df_conditions)}\")\n",
    "# df_conditions = df_conditions.drop_duplicates(subset=[\"condition_key\"])\n",
    "# print(f\"DEDUPED CONDITIONS {len(df_conditions)}\")\n",
    "\n",
    "# print(f\"STUDY CONDITIONS {len(df_study_conditions)}\")\n",
    "# df_study_conditions = df_study_conditions.drop_duplicates(subset=[\"condition_key\", \"study_key\"])\n",
    "# print(f\"DEDUPED STUDY CONDITIONS {len(df_study_conditions)}\")\n",
    "# print(\"----------------\")\n",
    "\n",
    "# print(f\"KEYWORDS {len(df_keywords)}\")\n",
    "# df_keywords = df_keywords.drop_duplicates(subset=[\"keyword_key\"])\n",
    "# print(f\"DEDUPED KEYWORDS {len(df_keywords)}\")\n",
    "\n",
    "# print(f\"STUDY KEYWORDS {len(df_study_keywords)}\")\n",
    "# df_study_keywords = df_study_keywords.drop_duplicates(subset=[\"keyword_key\", \"study_key\"])\n",
    "# print(f\"DEDUPED STUDY KEYWORDS {len(df_study_keywords)}\")\n",
    "# print(\"----------------\")\n",
    "\n",
    "\n",
    "# print(f\"INTERVENTIONS {len(df_interventions)}\")\n",
    "# df_interventions = df_interventions.drop_duplicates(subset=[\"intervention_key\"])\n",
    "# print(f\"DEDUPED INTERVENTIONS {len(df_interventions)}\")\n",
    "# print(\"----------------\")\n",
    "\n",
    "# print(f\"INTERVENTIONS OTHER {len(df_other_intervention_names)}\")\n",
    "# df_other_intervention_names = df_other_intervention_names.drop_duplicates(subset=[\"intervention_key\"])\n",
    "# print(f\"DEDUPED OTHER INTERVENTIONS {len(df_other_intervention_names)}\")\n",
    "# print(\"----------------\")\n",
    "\n",
    "\n",
    "# print(f\"STUDY INTERVENTIONS {len(df_study_interventions)}\")\n",
    "# df_study_interventions = df_study_interventions.drop_duplicates(subset=[\"intervention_key\", \"study_key\"])\n",
    "# print(f\"DEDUPED STUDY INTERVENTIONS {len(df_study_interventions)}\")\n",
    "# print(\"----------------\")\n",
    "\n",
    "\n",
    "# print(f\"STUDY INTERVENTION ALIASES {len(df_study_intervention_aliases)}\")\n",
    "\n",
    "# df_study_intervention_aliases = df_study_intervention_aliases.drop_duplicates(subset=[\"intervention_key\", \"study_key\"])\n",
    "# print(f\"DEDUPED STUDY INTERVENTION ALIASES {len(df_study_intervention_aliases)}\")\n",
    "# print(\"----------------\")\n",
    "\n",
    "\n",
    "# print(f\"Arm groups {len(df_arm_groups)}\")\n",
    "# df_arm_groups = df_arm_groups.drop_duplicates(subset=[\"study_key\", \"arm_group_key\"])\n",
    "# print(f\"DEDUPED Arm groups {len(df_arm_groups)}\")\n",
    "\n",
    "\n",
    "# print(f\"ARM GROUPS INTERVENTION {len(df_arm_interventions)}\")\n",
    "# df_arm_interventions = df_arm_interventions.drop_duplicates(subset=[\"arm_intervention_key\", \"study_key\", \"arm_group_key\"])\n",
    "# print(f\"DEDUPED ARM GROUPS INTERVENTION {len(df_arm_interventions)}\")\n",
    "# print(\"----------------\")\n",
    "\n",
    "\n",
    "# print(f\"primary outcomes {len(df_primary_outcomes)}\")\n",
    "# df_primary_outcomes = df_primary_outcomes.drop_duplicates(subset=[\"outcome_key\"])\n",
    "# print(f\"DEDUPED primary outcomes {len(df_primary_outcomes)}\")\n",
    "\n",
    "# print(f\"secondary outcomes {len(df_secondary_outcomes)}\")\n",
    "# df_secondary_outcomes = df_secondary_outcomes.drop_duplicates(subset=[\"outcome_key\"])\n",
    "# print(f\"DEDUPED secondary outcome {len(df_secondary_outcomes)}\")\n",
    "\n",
    "# print(f\"other outcomes {len(df_other_outcomes)}\")\n",
    "# df_other_outcomes = df_other_outcomes.drop_duplicates(subset=[\"outcome_key\"])\n",
    "# print(f\"DEDUPED other outcomes {len(df_other_outcomes)}\")\n",
    "\n",
    "\n",
    "# print(f\"CONTACTS {len(df_central_contacts)}\")\n",
    "# df_central_contacts = df_central_contacts.drop_duplicates(subset=[\"contact_key\"])\n",
    "# print(f\" DEDUPED CONTACTS {len(df_central_contacts)}\")\n",
    "\n",
    "# print(f\"STUDY CONTACTS {len(df_study_central_contacts)}\")\n",
    "# df_study_central_contacts = df_study_central_contacts.drop_duplicates(subset=[\"contact_key\", \"study_key\"])\n",
    "# print(f\"DEDUPED STUDY CONTACTS {len(df_study_central_contacts)}\")\n",
    "\n",
    "\n",
    "# print(f\"Locations {len(df_locations)}\")\n",
    "# df_locations = df_locations.drop_duplicates(subset=[\"location_key\"])\n",
    "# print(f\" DEDUPED Locations {len(df_locations)}\")\n",
    "\n",
    "\n",
    "# print(\"----------------\")\n",
    "\n",
    "# print(f\"REFERENCES {len(df_references)}\")\n",
    "# df_references = df_references.drop_duplicates(subset=[\"ref_key\"])\n",
    "# print(f\"DEDUPED REFERENCES {len(df_references)}\")\n",
    "\n",
    "\n",
    "# print(f\"LINKS {len(df_link_references)}\")\n",
    "# df_link_references = df_link_references.drop_duplicates(subset=[\"link_key\"])\n",
    "# print(f\"LINKS {len(df_link_references)}\")\n",
    "\n",
    "# print(\"----------------\")\n",
    "# print(f\"IPDS {len(df_ipd_references)}\")\n",
    "# df_ipd_references = df_ipd_references.drop_duplicates(subset=[\"ipd_key\"])\n",
    "# print(f\"DEDUPED IPDS {len(df_ipd_references)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"----------------\")\n",
    "# print(f\"condition mesh {len(df_conditions_mesh)}\")\n",
    "# df_conditions_mesh = df_conditions_mesh.drop_duplicates(subset=[\"mesh_key\"])\n",
    "# print(f\"DEDUPED condition mesh {len(df_conditions_mesh)}\")\n",
    "\n",
    "# print(\"----------------\")\n",
    "# print(f\"study condition mesh {len(df_study_conditions_mesh)}\")\n",
    "# df_study_conditions_mesh = df_study_conditions_mesh.drop_duplicates(subset=[\"mesh_key\", \"study_key\"])\n",
    "# print(f\"DEDUPED study condition mesh {len(df_study_conditions_mesh)}\")\n",
    "\n",
    "\n",
    "# print(\"----------------\")\n",
    "# print(f\"condition mesh ancestors {len(df_conditions_mesh_ancestors)}\")\n",
    "# df_conditions_mesh_ancestors = df_conditions_mesh_ancestors.drop_duplicates(subset=[\"ancestor_key\"])\n",
    "# print(f\"DEDUPED condition mesh ancestors {len(df_conditions_mesh_ancestors)}\")\n",
    "\n",
    "# print(\"----------------\")\n",
    "# print(f\"study condition mesh ancestors {len(df_study_conditions_mesh_ancestors)}\")\n",
    "# df_study_conditions_mesh_ancestors = df_study_conditions_mesh_ancestors.drop_duplicates(subset=[\"ancestor_key\", \"study_key\"])\n",
    "# print(f\"DEDUPED study condition mesh ancestors {len(df_study_conditions_mesh_ancestors)}\")\n",
    "\n",
    "\n",
    "# duplicates = df_study_conditions_mesh[\n",
    "#     df_study_conditions_mesh.duplicated(subset=[\"mesh_key\", \"study_key\"], keep=False)\n",
    "# ].sort_values([\"mesh_key\", \"study_key\"])\n",
    "\n",
    "# print(duplicates.head(10))\n",
    "# print(df_study_interventions.groupby(['study_key', 'intervention_key']).size().sort_values(ascending=False).head(20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7b033a6-a3f9-4d3e-9ed0-17232abbc46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_studies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "62006292-537f-4fd2-bb91-a55f8814bc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_studies.to_csv(\"data/study_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e64f2cdb-ff9a-4e98-82a9-31a28c031282",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_secondary_ids.to_csv(\"data/secondary_ids.csv\", index=False)\n",
    "df_nct_aliases.to_csv(\"data/nct_aliases.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c7406096-9193-4661-ac22-8c3076ea6bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sponsors.to_csv(\"data/sponsors.csv\", index=False)\n",
    "df_study_sponsors.to_csv(\"data/bridge_study_sponsors.csv\", index=False)\n",
    "df_collaborators.to_csv(\"data/collab.csv\", index=False)\n",
    "df_study_collaborators.to_csv(\"data/bridge_study_collab.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c84996e-9e44-44a8-9d60-130e464daf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conditions.to_csv(\"data/conditions.csv\", index=False)\n",
    "df_study_conditions.to_csv(\"data/study_conditions.csv\", index=False)\n",
    "df_keywords.to_csv(\"data/keywords.csv\", index=False)\n",
    "df_study_keywords.to_csv(\"data/study_keywords.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "02c6e76b-aacb-4eac-8534-f9e97fbc75b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arm_groups.to_csv(\"data/arms.csv\", index=False)\n",
    "df_arm_interventions.to_csv(\"data/arm_interventions.csv\", index=False)\n",
    "df_interventions.to_csv(\"data/interventions.csv\", index=False)\n",
    "df_study_interventions.to_csv(\"data/study_interventions.csv\", index=False)\n",
    "df_other_intervention_names.to_csv(\"data/other_intervention_names.csv\", index=False)\n",
    "df_study_intervention_aliases.to_csv(\"data/study_intervention_aliases.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c2f5da4a-e01e-4db9-bd79-157c5174aaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_primary_outcomes.to_csv(\"data/df_primary_outcomes.csv\", index=False)\n",
    "df_secondary_outcomes.to_csv(\"data/df_secondary_outcomes.csv\", index=False)\n",
    "df_other_outcomes.to_csv(\"data/df_other_outcomes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ba2b6a64-dbaf-4eb2-aeae-b21415898eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_central_contacts.to_csv(\"data/contacts.csv\", index=False)\n",
    "df_study_central_contacts.to_csv(\"data/study_contacts.csv\", index=False)\n",
    "df_study_locations.to_csv(\"data/study_locations.csv\", index=False)\n",
    "df_locations.to_csv(\"data/locations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8bcad372-6428-4450-b071-2b802ec50e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_references.to_csv(\"data/refs.csv\", index=False)\n",
    "df_link_references.to_csv(\"data/links.csv\", index=False)\n",
    "df_ipd_references.to_csv(\"data/ipds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed38ac1b-a7ac-44ec-80a7-e33348297e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outcome_measures.to_csv(\"data/df_outcome_measures.csv\", index=False)\n",
    "df_outcome_measure_groups.to_csv(\"data/df_outcome_measure_groups.csv\", index=False)\n",
    "df_outcome_measure_denom_units.to_csv(\"data/df_outcome_measure_denom_units.csv\", index=False)\n",
    "df_outcome_measure_denom_counts.to_csv(\"data/df_outcome_measure_denom_counts.csv\", index=False)\n",
    "df_outcome_measure_groups_result.to_csv(\"data/df_outcome_measure_groups_result.csv\", index=False)\n",
    "df_outcome_measure_analyses.to_csv(\"data/df_outcome_measure_analyses.csv\", index=False)\n",
    "df_outcome_measure_comparison_groups.to_csv(\"data/df_outcome_measure_comparison_groups.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81813a96-866b-41c3-bb0c-e132d0a31cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flow_groups.to_csv(\"data/df_flow_groups.csv\", index=False) \n",
    "df_flow_periods.to_csv(\"data/df_flow_periods.csv\", index=False) \n",
    "df_flow_period_milestones.to_csv(\"data/df_flow_period_milestones.csv\", index=False) \n",
    "df_flow_period_milestone_achievements.to_csv(\"data/df_flow_period_milestone_achievements.csv\", index=False) \n",
    "df_flow_period_withdrawals.to_csv(\"data/df_flow_period_withdrawals.csv\", index=False) \n",
    "df_flow_period_withdrawals.to_csv(\"data/df_flow_period_withdrawals.csv\", index=False) \n",
    "df_flow_period_withdrawal_reasons.to_csv(\"data/df_flow_period_withdrawal_reasons.csv\", index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fbcc3dbe-0799-4635-a91b-d99346e58224",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adverse_events.to_csv(\"data/df_adverse_events.csv\", index=False)\n",
    "df_event_groups.to_csv(\"data/df_event_groups.csv\", index=False) \n",
    "df_serious_events.to_csv(\"data/df_serious_events.csv\", index=False) \n",
    "df_serious_event_stats.to_csv(\"data/df_serious_event_stats.csv\", index=False) \n",
    "df_other_events.to_csv(\"data/df_other_events.csv\", index=False) \n",
    "df_other_event_stats.to_csv(\"data/df_other_event_stats.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0315d77c-201f-4825-96fa-fbce59716460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_violations.to_csv(\"data/df_violations.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9db26ac7-71b9-4afd-9bf2-d9bf706cf29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conditions_mesh.to_csv(\"data/df_conditions_mesh.csv\", index=False) \n",
    "df_study_conditions_mesh.to_csv(\"data/df_study_conditions_mesh.csv\", index=False) \n",
    "df_conditions_mesh_ancestors.to_csv(\"data/df_conditions_mesh_ancestors.csv\", index=False) \n",
    "df_study_conditions_mesh_ancestors.to_csv(\"data/df_study_conditions_mesh_ancestors.csv\", index=False) \n",
    "df_conditions_browse_leaves.to_csv(\"data/df_conditions_browse_leaves.csv\", index=False) \n",
    "df_study_conditions_browse_leaves.to_csv(\"data/df_study_conditions_browse_leaves.csv\", index=False) \n",
    "df_conditions_browse_branches.to_csv(\"data/df_conditions_browse_branches.csv\", index=False) \n",
    "df_study_conditions_browse_branches.to_csv(\"data/df_study_conditions_browse_branches.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "acc22025-d5ef-4867-8299-6f50544509a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interventions_mesh.to_csv(\"data/df_interventions_mesh.csv\", index=False) \n",
    "df_study_interventions_mesh.to_csv(\"data/df_study_interventions_mesh.csv\", index=False) \n",
    "df_interventions_mesh_ancestors.to_csv(\"data/df_interventions_mesh_ancestors.csv\", index=False) \n",
    "df_study_conditions_mesh_ancestors.to_csv(\"data/df_study_conditions_mesh_ancestors.csv\", index=False) \n",
    "df_interventions_browse_leaves.to_csv(\"data/df_interventions_browse_leaves.csv\", index=False) \n",
    "df_study_interventions_browse_leaves.to_csv(\"data/df_study_interventions_browse_leaves.csv\", index=False) \n",
    "df_interventions_browse_branches.to_csv(\"data/df_interventions_browse_branches.csv\", index=False) \n",
    "df_study_interventions_browse_branches.to_csv(\"data/df_study_interventions_browse_branches.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f4451a3-6791-41af-8e8a-5f66485029b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicates.to_csv(\"data/dups.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "24042ad7-6c37-40bb-b05c-d8067da904ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_key</th>\n",
       "      <th>nct_id</th>\n",
       "      <th>brief_title</th>\n",
       "      <th>official_title</th>\n",
       "      <th>acronym</th>\n",
       "      <th>org_study_id</th>\n",
       "      <th>brief_summary</th>\n",
       "      <th>detailed_desc</th>\n",
       "      <th>responsible_party</th>\n",
       "      <th>study_type</th>\n",
       "      <th>...</th>\n",
       "      <th>flow_type_units_analysed</th>\n",
       "      <th>certain_agreement_pi_sponsor_employee</th>\n",
       "      <th>certain_agreement_restrictive</th>\n",
       "      <th>certain_agreement_other_details</th>\n",
       "      <th>certain_agreement_restriction_type</th>\n",
       "      <th>sub_tracking_estimated_results_date</th>\n",
       "      <th>version_holder</th>\n",
       "      <th>has_results</th>\n",
       "      <th>last_updated</th>\n",
       "      <th>limitations_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>49387ab78594fffd</td>\n",
       "      <td>NCT00138086</td>\n",
       "      <td>Yttrium-90 Ibritumomab Tiuxetan (Zevalin) With...</td>\n",
       "      <td>Targeted Intensification by a New Preparative ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Z-BEAM</td>\n",
       "      <td>The objective of this study is to evaluate the...</td>\n",
       "      <td>The indolent course of the low-grade B-cell ly...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INTERVENTIONAL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2026-01-08</td>\n",
       "      <td>False</td>\n",
       "      <td>2006-09-08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            study_key       nct_id  \\\n",
       "688  49387ab78594fffd  NCT00138086   \n",
       "\n",
       "                                           brief_title  \\\n",
       "688  Yttrium-90 Ibritumomab Tiuxetan (Zevalin) With...   \n",
       "\n",
       "                                        official_title acronym org_study_id  \\\n",
       "688  Targeted Intensification by a New Preparative ...    None       Z-BEAM   \n",
       "\n",
       "                                         brief_summary  \\\n",
       "688  The objective of this study is to evaluate the...   \n",
       "\n",
       "                                         detailed_desc responsible_party  \\\n",
       "688  The indolent course of the low-grade B-cell ly...               NaN   \n",
       "\n",
       "         study_type  ... flow_type_units_analysed  \\\n",
       "688  INTERVENTIONAL  ...                      NaN   \n",
       "\n",
       "    certain_agreement_pi_sponsor_employee  certain_agreement_restrictive  \\\n",
       "688                                   NaN                            NaN   \n",
       "\n",
       "    certain_agreement_other_details certain_agreement_restriction_type  \\\n",
       "688                             NaN                                NaN   \n",
       "\n",
       "    sub_tracking_estimated_results_date version_holder has_results  \\\n",
       "688                                 NaN     2026-01-08       False   \n",
       "\n",
       "    last_updated limitations_desc  \n",
       "688   2006-09-08              NaN  \n",
       "\n",
       "[1 rows x 69 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_studies[df_studies['study_key'] == '49387ab78594fffd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be72ae0a-4d39-4b50-b480-8bcc04e52987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64788e20-586b-4573-8c77-d3bbff7522f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
