{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "41605e85-22b1-4de5-bb6b-d96a8c6fead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Any, Hashable, Tuple, Set\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d6d312e2-dade-492c-9033-aa55d0bc53a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGLE_FIELDS = {\n",
    "    # Identification\n",
    "    \"nct_id\": \"protocolSection.identificationModule.nctId\",\n",
    "    \"brief_title\": \"protocolSection.identificationModule.briefTitle\",\n",
    "    \"official_title\": \"protocolSection.identificationModule.officialTitle\",\n",
    "    \"acronym\": \"protocolSection.identificationModule.acronym\",\n",
    "    \"org_study_id\": \"protocolSection.identificationModule.orgStudyIdInfo.id\",\n",
    "    # Description\n",
    "    \"brief_summary\": \"protocolSection.descriptionModule.briefSummary\",\n",
    "    \"detailed_desc\": \"protocolSection.descriptionModule.detailedDescription\",\n",
    "\n",
    "    # Sponsor\n",
    "    \"responsible_party\": \"protocolSection.sponsorCollaboratorsModule.responsibleParty.type\",\n",
    "\n",
    "    # Design (single values)\n",
    "    \"study_type\": \"protocolSection.designModule.studyType\",\n",
    "    \"patient_registry\": \"protocolSection.designModule.patientRegistry\",\n",
    "    \"enrollment_type\": \"protocolSection.designModule.enrollmentInfo.type\",\n",
    "    \"enrollment_count\": \"protocolSection.designModule.enrollmentInfo.count\",\n",
    "    \"design_allocation\": \"protocolSection.designModule.designInfo.allocation\",\n",
    "    \"design_intervention_model\": \"protocolSection.designModule.designInfo.interventionModel\",\n",
    "    \"design_intervention_model_desc\": \"protocolSection.designModule.designInfo.interventionModelDescription\",\n",
    "    \"design_primary_purpose\": \"protocolSection.designModule.designInfo.primaryPurpose\",\n",
    "    \"design_observational_model\": \"protocolSection.designModule.designInfo.observationalModel\",\n",
    "    \"design_time_perspective\": \"protocolSection.designModule.designInfo.timePerspective\",\n",
    "    \"design_masking\": \"protocolSection.designModule.designInfo.maskingInfo.masking\",\n",
    "    # Biospecimen\n",
    "    \"biospec_retention\": \"protocolSection.designModule.bioSpec.retention\",\n",
    "    \"biospec_desc\": \"protocolSection.designModule.bioSpec.description\",\n",
    "    # Eligibility\n",
    "    \"eligibility_criteria\": \"protocolSection.eligibilityModule.eligibilityCriteria\",\n",
    "    \"healthy_volunteers\": \"protocolSection.eligibilityModule.healthyVolunteers\",\n",
    "    \"sex\": \"protocolSection.eligibilityModule.sex\",\n",
    "    \"min_age\": \"protocolSection.eligibilityModule.minimumAge\",\n",
    "    \"max_age\": \"protocolSection.eligibilityModule.maximumAge\",\n",
    "    \"population_desc\": \"protocolSection.eligibilityModule.studyPopulation\",\n",
    "    \"sampling_method\": \"protocolSection.eligibilityModule.samplingMethod\",\n",
    "    # Status\n",
    "    \"overall_status\": \"protocolSection.statusModule.overallStatus\",\n",
    "    \"last_known_status\": \"protocolSection.statusModule.lastKnownStatus\",\n",
    "    \"status_verified_date\": \"protocolSection.statusModule.statusVerifiedDate\",\n",
    "    \"start_date\": \"protocolSection.statusModule.startDateStruct.date\",\n",
    "    \"start_date_type\": \"protocolSection.statusModule.startDateStruct.type\",\n",
    "    \"first_submit_date\": \"protocolSection.statusModule.studyFirstSubmitDate\",\n",
    "    \"last_update_submit_date\": \"protocolSection.statusModule.lastUpdateSubmitDate\",\n",
    "    \"completion_date\": \"protocolSection.statusModule.completionDateStruct.date\",\n",
    "    \"completion_date_type\": \"protocolSection.statusModule.completionDateStruct.type\",\n",
    "    \"why_stopped\": \"protocolSection.statusModule.whyStopped\",\n",
    "    \"has_expanded_access\": \"protocolSection.statusModule.expandedAccessInfo.hasExpandedAccess\",\n",
    "    # Oversight\n",
    "    \"has_dmc\": \"protocolSection.oversightModule.oversightHasDmc\",\n",
    "    \"is_fda_regulated_drug\": \"protocolSection.oversightModule.isFdaRegulatedDrug\",\n",
    "    \"is_fda_regulated_device\": \"protocolSection.oversightModule.isFdaRegulatedDevice\",\n",
    "    \"is_unapproved_device\": \"protocolSection.oversightModule.isUnapprovedDevice\",\n",
    "    \"is_us_export\": \"protocolSection.oversightModule.isUsExport\",\n",
    "    # Individual participant data\n",
    "    \"ipd_sharing\": \"protocolSection.ipdSharingStatementModule.ipdSharing\",\n",
    "    \"ipd_desc\": \"protocolSection.ipdSharingStatementModule.description\",\n",
    "    \"ipd_time_frame\": \"protocolSection.ipdSharingStatementModule.timeFrame\",\n",
    "    \"ipd_access_criteria\": \"protocolSection.ipdSharingStatementModule.accessCriteria\",\n",
    "    \"ipd_url\": \"protocolSection.ipdSharingStatementModule.url\",\n",
    "    \n",
    "    # contacts\n",
    "    \"poc_title\": \"resultsSection.moreInfoModule.pointOfContact.title\",\n",
    "    \"poc_organization\": \"resultsSection.moreInfoModule.pointOfContact.organization\",\n",
    "    \"poc_email\": \"resultsSection.moreInfoModule.pointOfContact.email\",\n",
    "    \"poc_phone\": \"resultsSection.moreInfoModule.pointOfContact.phone\",\n",
    "    \"poc_phone_ext\": \"resultsSection.moreInfoModule.pointOfContact.phoneExt\",\n",
    "\n",
    "    # Participant flow\n",
    "    \"flow_pre_assignment_details\": \"resultsSection.participantFlowModule.preAssignmentDetails\",\n",
    "    \"flow_recruitment_details\": \"resultsSection.participantFlowModule.recruitmentDetails\",\n",
    "    \"flow_type_units_analysed\": \"resultsSection.participantFlowModule.typeUnitsAnalyzed\",\n",
    "    \n",
    "    # Certain agreements\n",
    "    \"certain_agreement_pi_sponsor_employee\": \"resultsSection.moreInfoModule.certainAgreement.piSponsorEmployee\",\n",
    "    \"certain_agreement_restrictive\": \"resultsSection.moreInfoModule.certainAgreement.restrictiveAgreement\",\n",
    "    \"certain_agreement_other_details\": \"resultsSection.moreInfoModule.certainAgreement.otherDetails\",\n",
    "    \"certain_agreement_restriction_type\": \"resultsSection.moreInfoModule.certainAgreement.restrictionType\",\n",
    "    \n",
    "    \n",
    "    # Submission tracking\n",
    "    \"sub_tracking_estimated_results_date\": \"derivedSection.miscInfoModule.submissionTracking.estimatedResultsFirstSubmitDate\",\n",
    "    \n",
    "    # Miscellaneous\n",
    "    \"version_holder\": \"derivedSection.miscInfoModule.versionHolder\",\n",
    "    \"has_results\": \"hasResults\",\n",
    "    \"last_updated\": \"protocolSection.statusModule.lastUpdatePostDateStruct.date\",\n",
    "    \"limitations_desc\": \"resultsSection.moreInfoModule.limitationsAndCaveats.description\",\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "175d0259-8edb-4167-84e4-5ce3635546b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NESTED_FIELDS = {\n",
    "    \"sponsor\": { #NOT NESTED BUT TREATED AS A SEPARATE DIM\n",
    "        \"index_field\": \"protocolSection.sponsorCollaboratorsModule.leadSponsor\",\n",
    "        \"object_type\": \"simple dict\",\n",
    "        \"fields\": [\n",
    "            (\"lead_sponsor_name\", \"name\"),\n",
    "            (\"lead_sponsor_class\", \"class\"),\n",
    "        ],\n",
    "        \"table_name\": \"sponsors\",\n",
    "        \"bridge_table_name\": \"study_sponsors\",\n",
    "        \"transformer_method\": \"extract_sponsors\",\n",
    "    },\n",
    "    \"collaborators\": {\n",
    "        \"index_field\": \"protocolSection.sponsorCollaboratorsModule.collaborators\",\n",
    "        \"object_type\": \"array_of_dicts\",\n",
    "        \"fields\": [\n",
    "            (\"sponsor_name\", \"name\"),\n",
    "            (\"sponsor_class\", \"class\"),\n",
    "        ],\n",
    "        \"table_name\": \"sponsor\",\n",
    "        \"bridge_table_name\": \"study_sponsors\",\n",
    "        \"transformer_method\": \"extract_sponsors\",\n",
    "    },\n",
    "    \"conditions\": {\n",
    "        \"index_field\": \"protocolSection.conditionsModule.conditions\",\n",
    "        \"object_type\": \"simple_array\",\n",
    "        \"table_name\": \"conditions\",\n",
    "        \"bridge_table_name\": \"bridge_study_conditions\",\n",
    "        \"field_name\": \"condition_name\",\n",
    "        \"transformer_method\": \"extract_conditions\",\n",
    "    },\n",
    "    \"keywords\": {\n",
    "        \"index_field\": \"protocolSection.conditionsModule.keywords\",\n",
    "        \"object_type\": \"simple_array\",\n",
    "        \"table_name\": \"keywords\",\n",
    "        \"bridge_table_name\": \"bridge_study_keywords\",\n",
    "        \"field_name\": \"keyword\",\n",
    "        \"transformer_method\": \"extract_keywords\",\n",
    "    },\n",
    "    \"interventions\": {\n",
    "        \"index_field\": \"protocolSection.armsInterventionsModule.interventions\",\n",
    "        \"object_type\": \"array_of_dicts\",\n",
    "        \"fields\": [\n",
    "            (\"intervention_name\", \"name\"),\n",
    "            (\"intervention_desc\", \"description\"),\n",
    "            (\"intervention_type\", \"type\"),\n",
    "        ],\n",
    "        \"table_name\": \"interventions\",\n",
    "        \"bridge_table_name\": \"bridge_study_interventions\",\n",
    "        \"transformer_method\": \"extract_interventions\",\n",
    "    },\n",
    "    \"arm_groups\": {\n",
    "        \"index_field\": \"protocolSection.armsInterventionsModule.armGroups\",\n",
    "        \"object_type\": \"array_of_dicts\",\n",
    "        \"table_name\": \"study_arm_group_interventions\",\n",
    "        \"fields\": [\n",
    "            (\"arm_group_label\", \"label\"),\n",
    "            (\"arm_group_type\", \"type\"),\n",
    "            (\"arm_group_desc\", \"description\"),\n",
    "        ],\n",
    "        \"transformer_method\": \"extract_arm_groups\",\n",
    "    },\n",
    "\n",
    "    \"central_contacts\": {\n",
    "        \"index_field\": \"protocolSection.contactsLocationsModule.centralContacts\",\n",
    "        \"object_type\": \"array_of_dicts\",\n",
    "        \"table_name\": \"contacts\",\n",
    "        \"bridge_table_name\": \"study_contacts\",\n",
    "        \"fields\": [\n",
    "            (\"name\", \"name\"),\n",
    "            (\"role\", \"role\"),\n",
    "            (\"email\", \"email\"),\n",
    "            (\"phone\", \"phone\"),\n",
    "            (\"phoneExt\", \"phoneExt\"),\n",
    "        ],\n",
    "        \"transformer_method\": \"extract_central_contacts\",\n",
    "    },\n",
    "    \"locations\": {\n",
    "        \"index_field\": \"protocolSection.contactsLocationsModule.locations\",\n",
    "        \"object_type\": \"array_of_dicts\",\n",
    "        \"table_name\": \"sites\",\n",
    "        \"bridge_table_name\": \"study_sites\",\n",
    "        \"fields\": [\n",
    "            (\"site_facility\", \"facility\"),\n",
    "            (\"city\", \"city\"),\n",
    "            (\"state\", \"state\"),\n",
    "            (\"zip\", \"zip\"),\n",
    "            (\"country\", \"country\"),\n",
    "            (\"site_status\", \"status\"),\n",
    "        ],\n",
    "        \"nested\": {\n",
    "            \"geoPoint\": {\n",
    "                \"object_type\": \"simple_dict\",\n",
    "                \"fields\": [\"lat\", \"lon\"],\n",
    "            },\n",
    "            #contacts are saved as a JSON blob\n",
    "            \"contacts\": {\n",
    "                \"object_type\": \"nested_array_of_dicts\",\n",
    "                \"table_name\": \"contacts\",\n",
    "                \"bridge_table_name\": \"location_contacts\",\n",
    "                \"fields\": [\n",
    "                    (\"name\", \"name\"),\n",
    "                    (\"role\", \"role\"),\n",
    "                    (\"email\", \"email\"),\n",
    "                    (\"phone\", \"phone\"),\n",
    "                    (\"phoneExt\", \"phoneExt\"),\n",
    "                ],\n",
    "                \"transformer_method\": \"extract_contacts\",\n",
    "            },\n",
    "        },\n",
    "        \"transformer_method\": \"extract_locations\",\n",
    "    },\n",
    "    #REFERENCES MODULE\n",
    "\n",
    "    \"references\": {\n",
    "        \"index_field\": \"protocolSection.referencesModule.references\",\n",
    "        \"object_type\": \"array_of_dicts\",\n",
    "        \"table_name\": \"study_publications\",\n",
    "        \"fields\": [\"pmid\", \"type\"],\n",
    "        \"transformer_method\": \"extract_references\",\n",
    "    },\n",
    "\n",
    "    \"see_also\": {\n",
    "        \"index_field\": \"protocolSection.referencesModule.seeAlsoLinks\",\n",
    "        \"object_type\": \"array_of_dicts\",\n",
    "        \"table_name\": \"study_see_also\",\n",
    "        \"fields\": [\"label\",  \"url\"],\n",
    "        \"transformer_method\": \"extract_links\",\n",
    "    },\n",
    "\n",
    "    \"avail_ipds\": {\n",
    "        \"index_field\": \"protocolSection.referencesModule.availIpds\",\n",
    "        \"object_type\": \"array_of_dicts\",\n",
    "        \"table_name\": \"study_ipds\",\n",
    "        \"fields\": [\"id\", \"type\", \"url\", \"comment\"],\n",
    "        \"transformer_method\": \"extract_ipds\",\n",
    "    },\n",
    "\n",
    "    # PARTICIPANT FLOW GROUPS\n",
    "    'flow_groups': {\n",
    "        'index_field': 'resultsSection.participantFlowModule.groups',\n",
    "        'type': 'array_of_dicts',\n",
    "        'bridge_table_name': 'study_flow_groups',\n",
    "        'fields': ['id', 'title', 'description'],\n",
    "        \"transformer_method\": \"extract_flow_groups\",\n",
    "    },\n",
    "\n",
    "    # PARTICIPANT FLOW PERIODS\n",
    "    'flow_periods': {\n",
    "        'index_field': 'resultsSection.participantFlowModule.periods',\n",
    "        'type': 'array_of_dicts',\n",
    "        'table_name': 'flow_periods',\n",
    "        'bridge_table_name': 'study_flow_periods',\n",
    "        'extract_fields': ['title'],\n",
    "        'nested': {\n",
    "            'milestones': ['type', 'comment', 'achievements'],\n",
    "            'dropWithdraws': ['type', 'comment', 'reasons']\n",
    "        },\n",
    "        \"transformer_method\": \"extract_milestone_achievements\",\n",
    "    },\n",
    "\n",
    "    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "2ac33a24-4e17-4358-942e-0b32aa4030a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_key(*args) -> str:\n",
    "    \"\"\"Generates a deterministic surrogate key from input values.\"\"\"\n",
    "    combined = \"|\".join(str(arg) for arg in args if arg is not None)\n",
    "    return hashlib.sha256(combined.encode()).hexdigest()[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "6acc5cf7-14a8-4164-9904-a69251bbd15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_study_fields(study_key: str, study_data: pd.Series) -> Dict:\n",
    "    study_record = dict()\n",
    "\n",
    "    study_record['study_key'] = study_key\n",
    "    for entity_key in SINGLE_FIELDS:\n",
    "        index_field = SINGLE_FIELDS.get(entity_key)\n",
    "\n",
    "        study_record[entity_key] = study_data.get(index_field)\n",
    "\n",
    "    return study_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "1eed3fbe-1ba6-4f19-bfe0-b61e60918e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sponsors(idx: int, study_key: str, study_data: pd.Series):\n",
    "\n",
    "    sponsors = []\n",
    "    study_sponsors = []\n",
    "\n",
    "    # Extract lead sponsor\n",
    "    lead_sponsor_index = NESTED_FIELDS[\"sponsor\"][\"index_field\"]\n",
    "\n",
    "    # sponsor name and class are scalar values and MUST be extracted directly\n",
    "    lead_sponsor_name = study_data.get(f'{lead_sponsor_index}.name')\n",
    "    lead_sponsor_class = study_data.get(f'{lead_sponsor_index}.class')\n",
    "\n",
    "    if pd.notna(lead_sponsor_name) and pd.notna(lead_sponsor_class):\n",
    "        sponsor_key = generate_key(\n",
    "            lead_sponsor_name, lead_sponsor_class\n",
    "        )\n",
    "        sponsors.append(\n",
    "            {\n",
    "                \"sponsor_key\": sponsor_key,\n",
    "                \"name\": lead_sponsor_name,\n",
    "                \"sponsor_class\": lead_sponsor_class,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        study_sponsors.append(\n",
    "            {\"study_key\": study_key, \"sponsor_key\": sponsor_key, \"is_lead\": True}\n",
    "        )\n",
    "    else:\n",
    "        print(f\"No lead sponsor found for {idx}\")\n",
    "\n",
    "    # Extract collaborators\n",
    "    collaborators_index = NESTED_FIELDS[\"collaborators\"][\"index_field\"]\n",
    "    collaborators_list = study_data.get(collaborators_index)\n",
    "\n",
    "    if isinstance(collaborators_list, (list, np.ndarray)) and len(collaborators_list) > 0:\n",
    "        for collaborator in collaborators_list:\n",
    "            sponsor_key = generate_key(\n",
    "                collaborator.get(\"name\"), collaborator.get(\"class\")\n",
    "            )\n",
    "\n",
    "            sponsors.append(\n",
    "                {\n",
    "                    \"sponsor_key\": sponsor_key,\n",
    "                    \"name\": collaborator.get(\"name\"),\n",
    "                    \"sponsor_class\": collaborator.get(\"class\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            study_sponsors.append(\n",
    "                {\"study_key\": study_key, \"sponsor_key\": sponsor_key, \"is_lead\": False}\n",
    "            )\n",
    "\n",
    "    return sponsors, study_sponsors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "3256cf6a-aaab-43e9-af9b-85e9c7c7a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_conditions(idx: int, study_key: str, study_data: pd.Series) -> Tuple | None:\n",
    "    conditions = []\n",
    "    study_conditions = []\n",
    "\n",
    "    conditions_index = NESTED_FIELDS[\"conditions\"][\"index_field\"]\n",
    "    conditions_list = study_data.get(conditions_index)\n",
    "\n",
    "\n",
    "    if isinstance(conditions_list, (list, np.ndarray)) and len(conditions_list) > 0:\n",
    "        for condition in conditions_list:\n",
    "            condition_key = generate_key(condition)\n",
    "\n",
    "            conditions.append(\n",
    "                {\"condition_key\": condition_key, \"condition_name\": condition}\n",
    "            )\n",
    "\n",
    "            study_conditions.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"condition_key\": condition_key,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return conditions, study_conditions\n",
    "\n",
    "    print(f\"No conditions found for {idx}\")\n",
    "    return conditions, study_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "cfb68545-c0da-4f92-a5cd-8ef7dc91c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(idx: Hashable, study_key: str, study_data: pd.Series) -> Tuple:\n",
    "    keywords = []\n",
    "    study_keywords = []\n",
    "\n",
    "    keywords_index = NESTED_FIELDS[\"keywords\"][\"index_field\"]\n",
    "    keywords_list = study_data.get(keywords_index)\n",
    "    if isinstance(keywords_list, (list, np.ndarray)) and len(keywords_list) > 0:\n",
    "        for keyword in keywords_list:\n",
    "            keyword_key = generate_key(keyword)\n",
    "\n",
    "            keywords.append({\"keyword_key\": keyword_key, \"keyword_name\": keyword})\n",
    "\n",
    "            study_keywords.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"keyword_key\": keyword_key,\n",
    "                }\n",
    "            )\n",
    "        \n",
    "    return keywords, study_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "f216152b-1ece-485e-bbd0-b09970159515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_interventions(idx: Hashable, study_key: str, study_data: pd.Series) -> Tuple:\n",
    "    intervention_names = []\n",
    "    study_interventions = []\n",
    "\n",
    "    interventions_index = NESTED_FIELDS[\"interventions\"][\"index_field\"]\n",
    "    interventions_list = study_data.get(interventions_index)\n",
    "\n",
    "    if isinstance(interventions_list, (list, np.ndarray)) and len(interventions_list) > 0:\n",
    "        for intervention in interventions_list:\n",
    "            main_name = intervention.get(\"name\")\n",
    "            intervention_type = intervention.get(\"type\")\n",
    "            description = intervention.get(\"description\")\n",
    "\n",
    "            intervention_key = generate_key(main_name, intervention_type)\n",
    "            intervention_names.append({\n",
    "                \"intervention_key\": intervention_key,\n",
    "                \"intervention_name\": main_name,\n",
    "                \"intervention_type\": intervention_type,\n",
    "                \"description\": description,\n",
    "               \n",
    "            })\n",
    "\n",
    "            study_interventions.append({\n",
    "                \"study_key\": study_key,\n",
    "                \"intervention_key\": intervention_key,\n",
    "                \"is_primary_name\": True\n",
    "            })\n",
    "\n",
    "\n",
    "            other_names = intervention.get(\"otherNames\")\n",
    "            if isinstance(other_names, (list, np.ndarray)) and len(other_names) > 0:\n",
    "                \n",
    "                for other_name in other_names:\n",
    "                    if other_name == main_name:\n",
    "                        continue #some studies put the main name in the list of other names\n",
    "                    intervention_key = generate_key(other_name, intervention_type)\n",
    "                    intervention_names.append({\n",
    "                        \"intervention_key\": intervention_key,\n",
    "                        \"intervention_name\": other_name,\n",
    "                        \"intervention_type\": intervention_type,\n",
    "                        \"description\": description,  # inherits from parent\n",
    "                       \n",
    "                    })\n",
    "\n",
    "                    study_interventions.append({\n",
    "                        \"study_key\": study_key,\n",
    "                        \"intervention_key\": intervention_key,\n",
    "                         \"is_primary_name\": False\n",
    "                    })\n",
    "    else:\n",
    "        pass\n",
    "        # print(f\"No interventions found for study {study_key}, {idx}\")\n",
    "    return intervention_names, study_interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "e5266ee0-27ba-4442-8bcf-b67852cce434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_arm_groups(idx: Hashable, study_key: str, study_data: pd.Series) -> List | None:\n",
    "    study_arms_interventions = []\n",
    "\n",
    "    study_arms_index = NESTED_FIELDS[\"arm_groups\"][\"index_field\"]\n",
    "    study_arms_list = study_data.get(study_arms_index)\n",
    "\n",
    "    if isinstance(study_arms_list, (list, np.ndarray)) and len(study_arms_list) > 0:\n",
    "        for study_arm in study_arms_list:\n",
    "            study_arm_label = study_arm.get(\"label\")\n",
    "            study_arm_description = study_arm.get(\"description\")\n",
    "            study_arm_type = study_arm.get(\"type\")\n",
    "\n",
    "            arm_intervention_key = generate_key(study_key, study_arm_label, study_arm_description,\n",
    "                                                     study_arm_type)\n",
    "            \n",
    "            arm_interventions = study_arm.get(\"interventionNames\")\n",
    "            if isinstance(arm_interventions, (list, np.ndarray)) and len(arm_interventions) > 0:\n",
    "\n",
    "                for intervention in arm_interventions:\n",
    "                    study_arms_interventions.append(\n",
    "                        {\n",
    "                            \"study_key\": study_key,\n",
    "                            \"arm_intervention_key\": arm_intervention_key,\n",
    "                            \"arm_label\": study_arm_label,\n",
    "                            \"arm_description\": study_arm_description,\n",
    "                            \"arm_type\": study_arm_type,\n",
    "                            \"arm_intervention_name\": intervention,\n",
    "                        }\n",
    "                    )\n",
    "            else:\n",
    "                study_arms_interventions.append(\n",
    "                    {\n",
    "                        \"study_key\": study_key,\n",
    "                        \"arm_intervention_key\": arm_intervention_key,\n",
    "                        \"arm_label\": study_arm_label,\n",
    "                        \"arm_description\": study_arm_description,\n",
    "                        \"arm_type\": study_arm_type,\n",
    "                        \"arm_intervention_name\": None,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return study_arms_interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "79d49e8b-f99a-45bf-994b-331d0acbdaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_central_contacts(idx: Hashable, study_key: str, study_data: pd.Series) -> Tuple:\n",
    "    central_contacts = []\n",
    "    study_central_contacts = []\n",
    "\n",
    "    central_contacts_index = NESTED_FIELDS[\"central_contacts\"][\"index_field\"]\n",
    "    central_contacts_list = study_data.get(central_contacts_index)\n",
    "\n",
    "    if isinstance(central_contacts_list, (list, np.ndarray)) and len(central_contacts_list) > 0:\n",
    "\n",
    "        for central_contact in central_contacts_list:\n",
    "            name = central_contact.get(\"name\")\n",
    "            role = central_contact.get(\"role\")\n",
    "            phone = central_contact.get(\"phone\")\n",
    "            email = central_contact.get(\"email\")\n",
    "\n",
    "            central_contact_key = generate_key(name, role, phone, email)\n",
    "\n",
    "            central_contacts.append(\n",
    "                {\"contact_key\": central_contact_key,\n",
    "                 \"contact_name\": name,\n",
    "                 \"contact_role\": role,\n",
    "                 \"contact_phone\": phone,\n",
    "                 \"contact_email\": email,\n",
    "                 })\n",
    "\n",
    "            study_central_contacts.append(\n",
    "                {\n",
    "                    \"study_key\": study_key,\n",
    "                    \"contact_key\": central_contact_key,\n",
    "                }\n",
    "            )\n",
    "    return central_contacts, study_central_contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "67b65fd9-6808-450e-acd0-e3d964bb40f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_location_status(location_statuses: Set) -> str:\n",
    "    if not location_statuses:\n",
    "        return \"UNKNOWN\"\n",
    "\n",
    "    if len(location_statuses) == 1:\n",
    "        return list(location_statuses)[0]\n",
    "\n",
    "    # progression case\n",
    "    if location_statuses == {\"RECRUITING\", \"NOT_YET_RECRUITING\"}:\n",
    "        return \"RECRUITING\"\n",
    "\n",
    "    final_statuses = [\"COMPLETED\", \"TERMINATED\", \"WITHDRAWN\"]\n",
    "\n",
    "    if \"RECRUITING\" in location_statuses:\n",
    "        for final_status in final_statuses:\n",
    "            if final_status in location_statuses:\n",
    "                return final_status  # study ended, can't recruit\n",
    "\n",
    "        # RECRUITING plus other ambiguous statuses\n",
    "        return \"RECRUITING_STATUS_UNCLEAR\"\n",
    "\n",
    "    # Multiple non-recruiting statuses - anyone works. makes no difference\n",
    "    return list(location_statuses)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "8cc46680-e247-428b-be4a-5a3f88af389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_locations(idx: Hashable, study_key: str, study_data: pd.Series) -> Tuple:\n",
    "    \"\"\"\n",
    "    Extract locations with status resolution\n",
    "    \"\"\"\n",
    "    locations = []\n",
    "    study_locations = []\n",
    "\n",
    "\n",
    "    locations_index = NESTED_FIELDS[\"locations\"][\"index_field\"]\n",
    "    locations_list = study_data.get(locations_index)\n",
    "\n",
    "    if isinstance(locations_list, (list, np.ndarray)) and len(locations_list) > 0:\n",
    "        for location in locations_list:\n",
    "            facility = location.get(\"facility\")\n",
    "            city = location.get(\"city\")\n",
    "            state = location.get(\"state\")\n",
    "            country = location.get(\"country\")\n",
    "            \n",
    "            location_key = generate_key(facility, city, state, country)\n",
    "            curr_location = {\n",
    "                \"location_key\": location_key,\n",
    "                \"facility\": facility,\n",
    "                \"city\": city,\n",
    "                \"state\": state,\n",
    "                \"country\": state,\n",
    "\n",
    "            }\n",
    "            geopoint = location.get(\"geoPoint\")\n",
    "            if isinstance(geopoint, dict) and geopoint:\n",
    "                curr_location[\"lat\"] = float(geopoint.get(\"lat\")) if geopoint.get(\"lat\") else None\n",
    "                curr_location[\"lon\"] = float(geopoint.get(\"lon\")) if geopoint.get(\"lon\") else None\n",
    "\n",
    "            locations.append(curr_location)\n",
    "\n",
    "            # resolve location status\n",
    "            statuses = [loc.get(\"status\") for loc in locations if loc.get(\"status\")]\n",
    "            unique_statuses = set(statuses)\n",
    "\n",
    "            resolved_status = resolve_location_status(unique_statuses)\n",
    "\n",
    "            study_locations.append({\n",
    "                \"study_key\": study_key,\n",
    "                \"location_key\": location_key,\n",
    "                \"status\": resolved_status,\n",
    "                \"status_type\": \"\", #aCTUAL or inferred\n",
    "                \"contacts\": location.get(\"contacts\"),\n",
    "\n",
    "            })\n",
    "\n",
    "    return locations, study_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "ba23b204-7ec9-4cff-b969-8e4a65297cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_references(idx: Hashable, study_key: str, study_data: pd.Series) -> List:\n",
    "\n",
    "    study_references = []\n",
    "\n",
    "    references_index = NESTED_FIELDS[\"references\"][\"index_field\"]\n",
    "    references_list = study_data.get(references_index)\n",
    "\n",
    "    if isinstance(references_list, (list, np.ndarray)) and len(references_list) > 0:\n",
    "\n",
    "        for reference in references_list:\n",
    "            pmid = reference.get('pmid')\n",
    "            reference_key = generate_key(study_key, pmid)\n",
    "            study_references.append({\n",
    "                \"study_key\": study_key,\n",
    "                \"ref_key\": reference_key,\n",
    "                \"pmid\": pmid,\n",
    "                \"type\": reference.get(\"type\"),\n",
    "                \"citation\": reference.get(\"citation\")\n",
    "             })\n",
    "\n",
    "    return study_references\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "b53115e4-23fd-44d9-a403-7647659cb1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_links(idx: Hashable, study_key: str, study_data: pd.Series) -> List:\n",
    "    study_links = []\n",
    "\n",
    "    links_index = NESTED_FIELDS[\"see_also\"][\"index_field\"]\n",
    "    links_list = study_data.get(links_index)\n",
    "\n",
    "    if isinstance(links_list, (list, np.ndarray)) and len(links_list) > 0:\n",
    "        for link in links_list:\n",
    "            label = link.get('label')\n",
    "            link_key = generate_key(study_key, label)\n",
    "            study_links.append({\n",
    "                \"study_key\": study_key,\n",
    "                \"link_key\": link_key,\n",
    "                \"label\": label,\n",
    "                \"url\": link.get(\"url\")\n",
    "            })\n",
    "\n",
    "    return study_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "d3bdbbf2-5429-4dae-b1ad-8c5b5b5d57f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ipds(idx: Hashable, study_key: str, study_data: pd.Series) -> List:\n",
    "    study_ipds = []\n",
    "\n",
    "    ipds_index = NESTED_FIELDS[\"avail_ipds\"][\"index_field\"]\n",
    "    ipds_list = study_data.get(ipds_index)\n",
    "\n",
    "    if isinstance(ipds_list, (list, np.ndarray)) and len(ipds_list) > 0:\n",
    "\n",
    "        for ipd in ipds_list:\n",
    "            ipd_id = ipd.get('id')\n",
    "            ipd_type = ipd.get('type')\n",
    "            ipd_url = ipd.get('url')\n",
    "\n",
    "            ipd_key = generate_key(study_key, ipd_id, ipd_type, ipd_url)\n",
    "            study_ipds.append({\n",
    "                \"study_key\": study_key,\n",
    "                \"ipd_key\": ipd_key,\n",
    "                \"id\": ipd_id,\n",
    "                \"type\": ipd_type,\n",
    "                \"url\": ipd_url,\n",
    "                \"comment\": ipd.get(\"comment\")\n",
    "            })\n",
    "\n",
    "    return study_ipds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "2c4ac9cb-21e1-4b82-8a57-ef29d123293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_flow_groups(idx: Hashable, study_key: str, study_data: pd.Series) -> List:\n",
    "    study_flow_groups = []\n",
    "\n",
    "    flow_index = NESTED_FIELDS[\"flow_groups\"][\"index_field\"]\n",
    "    flow_group_list = study_data.get(flow_index)\n",
    "\n",
    "    if isinstance(flow_group_list, (list, np.ndarray)) and len(flow_group_list) > 0:\n",
    "        for flow in flow_group_list:\n",
    "            group_id = flow.get('id')\n",
    "            group_key = generate_key(study_key, group_id)\n",
    "\n",
    "            study_flow_groups.append({\n",
    "                \"study_key\": study_key,\n",
    "                \"group_key\": group_key,\n",
    "                \"group_id\": group_id,\n",
    "                \"title\": flow.get(\"title\"),\n",
    "                \"description\": flow.get(\"description\")\n",
    "\n",
    "            })\n",
    "\n",
    "    return study_flow_groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "1a40bccb-4fb7-412b-9391-214dbc5c45b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_flow_events(idx: Hashable, study_key: str, study_data: pd.Series) -> List:\n",
    "    flow_period_events = []\n",
    "\n",
    "    flow_index = NESTED_FIELDS[\"flow_periods\"][\"index_field\"]\n",
    "    flow_period_list = study_data.get(flow_index)\n",
    "\n",
    "    if isinstance(flow_period_list, (list, np.ndarray)) and len(flow_period_list) > 0:\n",
    "        for period in flow_period_list:\n",
    "            period_title = period.get('title')\n",
    "            period_key = generate_key(study_key, period_title)\n",
    "\n",
    "            period_milestones = period.get('milestones')\n",
    "            if isinstance(period_milestones, (list, np.ndarray)) and len(period_milestones) > 0:\n",
    "                for period_milestone in period_milestones:\n",
    "                    milestone_type = period_milestone.get('type')\n",
    "                    milestone_achievements = period_milestone.get('achievements')\n",
    "\n",
    "                    if isinstance(milestone_achievements, (list, np.ndarray)) and len(milestone_achievements) > 0:\n",
    "                        for achievement in milestone_achievements:\n",
    "                            flow_period_events.append({\n",
    "                                \"study_key\": study_key,\n",
    "                                \"period_key\": period_key,\n",
    "                                \"event_class\": \"ACHIEVEMENT\",\n",
    "                                \"event_type\": milestone_type,\n",
    "                                \"period_title\": period_title,\n",
    "                                \"group_id\": achievement.get('groupId'),\n",
    "                                \"num_subjects\": achievement.get('numSubjects'),\n",
    "\n",
    "                            })\n",
    "                    else:\n",
    "                        flow_period_events.append({\n",
    "                            \"study_key\": study_key,\n",
    "                            \"event_class\": \"ACHIEVEMENT\",\n",
    "                            \"event_type\": milestone_type,\n",
    "                            \"period_key\": period_key,\n",
    "                            \"period_title\": period_title,\n",
    "\n",
    "                            \"group_id\":\"UNKNOWN\",\n",
    "                            \"num_subjects\": None, #not 0\n",
    "\n",
    "                        })\n",
    "\n",
    "            period_withdrawals = period.get('dropWithdraws')\n",
    "            if isinstance(period_withdrawals, (list, np.ndarray)) and len(period_withdrawals) > 0:\n",
    "                for withdrawal in period_withdrawals:\n",
    "                    withdrawal_type = withdrawal.get('type')\n",
    "                    withdrawal_reasons = withdrawal.get('reasons')\n",
    "\n",
    "                    if isinstance(withdrawal_reasons, (list, np.ndarray)) and len(withdrawal_reasons) > 0:\n",
    "                        for reason in withdrawal_reasons:\n",
    "                            flow_period_events.append({\n",
    "                                \"study_key\": study_key,\n",
    "                                \"period_key\": period_key,\n",
    "                                \"event_class\": \"WITHDRAWAL\",\n",
    "                                \"event_type\": withdrawal_type,\n",
    "                                \"period_title\": period_title,\n",
    "                                \"group_id\": reason.get('groupId'),\n",
    "                                \"num_subjects\": reason.get('numSubjects'),\n",
    "\n",
    "                            })\n",
    "                    else:\n",
    "                        flow_period_events.append({\n",
    "                            \"study_key\": study_key,\n",
    "                            \"event_class\": \"WITHDRAWAL\",\n",
    "                            \"event_type\": withdrawal_type,\n",
    "                            \"period_key\": period_key,\n",
    "                            \"period_title\": period_title,\n",
    "                            \"group_id\":\"UNKNOWN\",\n",
    "                            \"num_subjects\": None, #not 0\n",
    "\n",
    "                        })\n",
    "\n",
    "\n",
    "\n",
    "    return flow_period_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563cd50a-5e2d-4c23-8203-db7d8926fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_studies = []\n",
    "all_sponsors = []\n",
    "all_study_sponsors = []\n",
    "\n",
    "all_conditions = []\n",
    "all_study_conditions = []\n",
    "\n",
    "all_keywords = []\n",
    "all_study_keywords = []\n",
    "\n",
    "all_arm_group_interventions = []\n",
    "\n",
    "all_interventions = []\n",
    "all_interventions_other_names = []\n",
    "all_study_interventions = []\n",
    "\n",
    "all_locations = []\n",
    "all_study_locations = []\n",
    "all_central_contacts = []\n",
    "all_study_central_contacts = []\n",
    "\n",
    "all_study_references = []\n",
    "all_study_links = []\n",
    "\n",
    "all_ipds = []\n",
    "\n",
    "all_flow_groups = []\n",
    "all_flow_period_events = []\n",
    "\n",
    "\n",
    "df = pd.read_parquet(\"1.parquet\")\n",
    "df_studies = pd.json_normalize(df['studies'].tolist())\n",
    "\n",
    "for idx, study in df_studies.iterrows():\n",
    "    nct_index = SINGLE_FIELDS['nct_id']\n",
    "    nct_id = study.get(nct_index)\n",
    "    \n",
    "    study_key = generate_key(nct_id)\n",
    "\n",
    "\n",
    "    #study\n",
    "    study_record = extract_study_fields(study_key, study)\n",
    "    all_studies.append(study_record)\n",
    "\n",
    "    # sponsors\n",
    "    sponsors, study_sponsors = extract_sponsors(idx, study_key, study)\n",
    "    all_sponsors.extend(sponsors)\n",
    "    all_study_sponsors.extend(study_sponsors)\n",
    "\n",
    "    # conditions and keywords\n",
    "    conditions, study_conditions = extract_conditions(idx, study_key, study)\n",
    "    all_conditions.extend(conditions)\n",
    "    all_study_conditions.extend(study_conditions)\n",
    "\n",
    "    keywords, study_keywords = extract_keywords(idx, study_key, study)\n",
    "    all_keywords.extend(keywords)\n",
    "    all_study_keywords.extend(study_keywords)\n",
    "\n",
    "\n",
    "    # groups and interventions\n",
    "    arm_group_interventions = extract_arm_groups(idx, study_key, study)\n",
    "    all_arm_group_interventions.extend(arm_group_interventions)\n",
    "\n",
    "    interventions, study_interventions = extract_interventions(idx, study_key, study)\n",
    "    all_interventions.extend(interventions)\n",
    "    all_study_interventions.extend(study_interventions)\n",
    "\n",
    "    # contacts and locations\n",
    "    central_contacts, study_central_contacts  = extract_central_contacts(idx, study_key, study)\n",
    "    all_central_contacts.extend(central_contacts)\n",
    "    all_study_central_contacts.extend(study_central_contacts)\n",
    "\n",
    "    locations, study_locations = extract_locations(idx, study_key, study)\n",
    "    all_locations.extend(locations)\n",
    "    all_study_locations.extend(study_locations)\n",
    "\n",
    "\n",
    "    #links and references\n",
    "    references = extract_references(idx, study_key, study)\n",
    "    all_study_references.extend(references)\n",
    "\n",
    "    links = extract_links(idx, study_key, study)\n",
    "    all_study_links.extend(links)\n",
    "\n",
    "    ipds = extract_ipds(idx, study_key, study)\n",
    "    all_ipds.extend(ipds)\n",
    "\n",
    "    flow_groups = extract_flow_groups(idx,study_key, study)\n",
    "    all_flow_groups.extend(flow_groups)\n",
    "\n",
    "    flow_period_events = extract_flow_events(idx, study_key, study)\n",
    "    all_flow_period_events.extend(flow_period_events)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "studies = pd.DataFrame(all_studies)\n",
    "\n",
    "df_sponsors = pd.DataFrame(all_sponsors)\n",
    "df_study_sponsors = pd.DataFrame(all_study_sponsors)\n",
    "\n",
    "df_conditions = pd.DataFrame(all_conditions)\n",
    "df_study_conditions= pd.DataFrame(all_study_conditions)\n",
    "\n",
    "df_keywords = pd.DataFrame(all_keywords)\n",
    "df_study_keywords = pd.DataFrame(all_study_keywords)\n",
    "\n",
    "df_arm_group_interventions = pd.DataFrame(all_arm_group_interventions)\n",
    "df_interventions = pd.DataFrame(all_interventions)\n",
    "df_study_interventions = pd.DataFrame(all_study_interventions)\n",
    "\n",
    "\n",
    "df_central_contacts = pd.DataFrame(all_central_contacts)\n",
    "df_study_central_contacts = pd.DataFrame(all_study_central_contacts)\n",
    "df_locations = pd.DataFrame(all_locations)\n",
    "df_study_locations = pd.DataFrame(all_study_locations)\n",
    "\n",
    "\n",
    "df_references = pd.DataFrame(all_study_references)\n",
    "df_links = pd.DataFrame(all_study_links)\n",
    "\n",
    "df_ipds = pd.DataFrame(all_ipds)\n",
    "\n",
    "df_flow_groups = pd.DataFrame(all_flow_groups)\n",
    "df_flow_period_events = pd.DataFrame(all_flow_period_events)\n",
    "\n",
    "\n",
    "print(\"----------------\")\n",
    "print(f\"STUDIES {len(studies)}\")\n",
    "print(\"----------------\")\n",
    "\n",
    "\n",
    "#dedupe and inspect\n",
    "print(f\"SPONSORS {len(df_sponsors)}\")\n",
    "df_sponsors = df_sponsors.drop_duplicates(subset=[\"sponsor_key\"])\n",
    "print(f\"DEDUPED SPONSORS {len(df_sponsors)}\")\n",
    "\n",
    "print(f\"STUDY SPONSORS {len(df_study_sponsors)}\")\n",
    "df_study_sponsors = df_study_sponsors.drop_duplicates(subset=[\"sponsor_key\", \"study_key\"])\n",
    "print(f\"DEDUPED STUDY SPONSORS {len(df_study_sponsors)}\")\n",
    "print(\"----------------\")\n",
    "\n",
    "print(f\"CONDITIONS {len(df_conditions)}\")\n",
    "df_conditions = df_conditions.drop_duplicates(subset=[\"condition_key\"])\n",
    "print(f\"DEDUPED CONDITIONS {len(df_conditions)}\")\n",
    "\n",
    "print(f\"STUDY CONDITIONS {len(df_study_conditions)}\")\n",
    "df_study_conditions = df_study_conditions.drop_duplicates(subset=[\"condition_key\", \"study_key\"])\n",
    "print(f\"DEDUPED STUDY CONDITIONS {len(df_study_conditions)}\")\n",
    "print(\"----------------\")\n",
    "\n",
    "print(f\"KEYWORDS {len(df_keywords)}\")\n",
    "df_keywords = df_keywords.drop_duplicates(subset=[\"keyword_key\"])\n",
    "print(f\"DEDUPED KEYWORDS {len(df_keywords)}\")\n",
    "\n",
    "print(f\"STUDY KEYWORDS {len(df_study_keywords)}\")\n",
    "df_study_keywords = df_study_keywords.drop_duplicates(subset=[\"keyword_key\", \"study_key\"])\n",
    "print(f\"DEDUPED STUDY KEYWORDS {len(df_study_keywords)}\")\n",
    "print(\"----------------\")\n",
    "\n",
    "\n",
    "# duplicates = df_study_interventions[\n",
    "#     df_study_interventions.duplicated(subset=[\"intervention_key\", \"study_key\"], keep=False)\n",
    "# ].sort_values([\"study_key\", \"intervention_key\"])\n",
    "# print(df_study_interventions.groupby(['study_key', 'intervention_key']).size().sort_values(ascending=False).head(20))\n",
    "# print(duplicates.head(20))\n",
    "\n",
    "\n",
    "print(f\"INTERVENTIONS {len(df_interventions)}\")\n",
    "df_interventions = df_interventions.drop_duplicates(subset=[\"intervention_key\"])\n",
    "print(f\"DEDUPED INTERVENTIONS {len(df_interventions)}\")\n",
    "\n",
    "print(f\"STUDY INTERVENTIONS {len(df_study_interventions)}\")\n",
    "df_study_interventions = df_study_interventions.drop_duplicates(subset=[\"intervention_key\", \"study_key\"])\n",
    "print(f\"DEDUPED STUDY INTERVENTIONS {len(df_study_interventions)}\")\n",
    "print(\"----------------\")\n",
    "\n",
    "\n",
    "print(f\"ARM GROUPS INTERVENTION {len(df_arm_group_interventions)}\")\n",
    "df_arm_group_interventions = df_arm_group_interventions.drop_duplicates(subset=[\"arm_intervention_key\", \"study_key\", \"arm_intervention_name\"])\n",
    "print(f\"DEDUPED ARM GROUPS INTERVENTION {len(df_arm_group_interventions)}\")\n",
    "print(\"----------------\")\n",
    "\n",
    "print(f\"LOCATIONS {len(df_locations)}\")\n",
    "df_locations = df_locations.drop_duplicates(subset=[\"location_key\"])\n",
    "print(f\" DEDUPED LOCATIONS {len(df_locations)}\")\n",
    "\n",
    "print(f\" STUDY LOCATIONS {len(df_study_locations)}\")\n",
    "\n",
    "# duplicates = df_study_locations[\n",
    "#     df_study_locations.duplicated(subset=[\"study_key\", \"location_key\"], keep=False)\n",
    "# ]\n",
    "# print(duplicates.head(20))\n",
    "\n",
    "\n",
    "df_study_locations = df_study_locations.drop_duplicates(subset=[\"location_key\", \"study_key\"])\n",
    "print(f\" DEDUPED STUDY LOCATIONS {len(df_study_locations)}\")\n",
    "print(\"----------------\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"CONTACTS {len(df_central_contacts)}\")\n",
    "df_central_contacts = df_central_contacts.drop_duplicates(subset=[\"contact_key\"])\n",
    "print(f\" DEDUPED CONTACTS {len(df_central_contacts)}\")\n",
    "\n",
    "print(f\"STUDY CONTACTS {len(df_study_central_contacts)}\")\n",
    "df_study_central_contacts = df_study_central_contacts.drop_duplicates(subset=[\"contact_key\", \"study_key\"])\n",
    "print(f\"DEDUPED STUDY CONTACTS {len(df_study_central_contacts)}\")\n",
    "\n",
    "print(\"----------------\")\n",
    "\n",
    "print(f\"REFERENCES {len(df_references)}\")\n",
    "df_references = df_references.drop_duplicates(subset=[\"study_key\", \"ref_key\"])\n",
    "print(f\"DEDUPED REFERENCES {len(df_references)}\")\n",
    "\n",
    "print(f\"LINKS {len(df_links)}\")\n",
    "df_links = df_links.drop_duplicates(subset=[\"study_key\", \"link_key\", \"url\"])\n",
    "print(f\"LINKS {len(df_links)}\")\n",
    "\n",
    "print(\"----------------\")\n",
    "print(f\"IPDS {len(df_ipds)}\")\n",
    "df_ipds = df_ipds.drop_duplicates(subset=[\"study_key\", \"ipd_key\"])\n",
    "print(f\"DEDUPED IPDS {len(df_ipds)}\")\n",
    "\n",
    "print(\"----------------\")\n",
    "print(f\"FLOW GROUPS {len(df_flow_groups)}\")\n",
    "df_flow_groups = df_flow_groups.drop_duplicates(subset=[\"study_key\", \"group_key\"])\n",
    "print(f\"DEDUPED FLOW GROUPS {len(df_flow_groups)}\")\n",
    "\n",
    "duplicates = df_flow_period_events[\n",
    "    df_flow_period_events.duplicated(subset=[\"study_key\", \"period_key\", \"group_id\", \"event_class\", \"event_type\" ], keep=False)\n",
    "]\n",
    "print(duplicates.head(10))\n",
    "print(f\"EVENTS {len(df_flow_period_events)}\")\n",
    "df_flow_period_events = df_flow_period_events.drop_duplicates(subset=[\"study_key\", \"period_key\", \"group_id\", \"event_class\", \"event_type\" ])\n",
    "print(f\"DEDUPED Events {len(df_flow_period_events)}\")\n",
    "print(\"----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "62006292-537f-4fd2-bb91-a55f8814bc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "studies.to_csv(\"data/study_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7406096-9193-4661-ac22-8c3076ea6bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sponsors.to_csv(\"data/sponsors.csv\", index=False)\n",
    "df_study_sponsors.to_csv(\"data/bridge_study_sponsors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c84996e-9e44-44a8-9d60-130e464daf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conditions.to_csv(\"data/conditions.csv\", index=False)\n",
    "df_study_conditions.to_csv(\"data/study_conditions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cec77e2-889c-456d-9d9b-815c6604cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords.to_csv(\"data/keywords.csv\", index=False)\n",
    "df_study_keywords.to_csv(\"data/study_keywords.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c6e76b-aacb-4eac-8534-f9e97fbc75b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interventions.to_csv(\"data/interventions.csv\", index=False)\n",
    "df_study_interventions.to_csv(\"data/study_interventions.csv\", index=False)\n",
    "df_arm_group_interventions.to_csv(\"data/arm_groups_intrv.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b6a64-dbaf-4eb2-aeae-b21415898eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_central_contacts.to_csv(\"data/contacts.csv\", index=False)\n",
    "df_study_central_contacts.to_csv(\"data/study_contacts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7e66f934-8584-4f2e-b8d0-337c754d48c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_study_locations.to_csv(\"data/study_locations.csv\", index=False)\n",
    "df_locations.to_csv(\"data/locations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "506f37e2-e57a-463c-abc3-aaab3782df8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# studies[studies['study_key'] == 'e5631c51402e5389']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8bcad372-6428-4450-b071-2b802ec50e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_references.to_csv(\"data/refs.csv\", index=False)\n",
    "df_links.to_csv(\"data/links.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ed38ac1b-a7ac-44ec-80a7-e33348297e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ipds.to_csv(\"data/ipds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "2654c06e-cc2b-4c09-9924-3027c20a4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flow_groups.to_csv(\"data/flow_groups.csv\", index=False)\n",
    "df_flow_period_events.to_csv(\"data/flow_events.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4451a3-6791-41af-8e8a-5f66485029b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
